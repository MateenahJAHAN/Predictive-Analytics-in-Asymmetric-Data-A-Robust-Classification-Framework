{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoanTap Loan Default Prediction Using Logistic Regression\n",
    "\n",
    "## A Comprehensive Classification Framework for Credit Risk Assessment\n",
    "\n",
    "**Author:** Vidyasagar — Data Scientist  \n",
    "**Date:** February 2026  \n",
    "**Version:** 1.0\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "1. [Problem Statement & Business Context](#1)\n",
    "2. [Data Loading & Initial Exploration](#2)\n",
    "3. [Exploratory Data Analysis (EDA)](#3)\n",
    "   - 3.1 Univariate Analysis\n",
    "   - 3.2 Bivariate Analysis\n",
    "   - 3.3 Correlation Analysis\n",
    "4. [Data Preprocessing](#4)\n",
    "   - 4.1 Duplicate & Missing Value Treatment\n",
    "   - 4.2 Outlier Treatment\n",
    "   - 4.3 Feature Engineering\n",
    "   - 4.4 Data Preparation for Modeling\n",
    "5. [Model Building — Logistic Regression](#5)\n",
    "6. [Results Evaluation](#6)\n",
    "   - 6.1 Classification Report & Confusion Matrix\n",
    "   - 6.2 ROC AUC Curve\n",
    "   - 6.3 Precision-Recall Curve\n",
    "7. [Precision vs Recall Tradeoff](#7)\n",
    "8. [Actionable Insights & Recommendations](#8)\n",
    "9. [Questionnaire Answers](#9)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Problem Statement & Business Context\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "**LoanTap** is an online platform committed to delivering customized loan products to millennials. The core challenge in the lending industry is to differentiate between borrowers who will **fully repay** their loans and those who will **default** (Charged Off).\n",
    "\n",
    "### Business Objective\n",
    "\n",
    "Build a **Logistic Regression model** that can:\n",
    "- Accurately predict whether a borrower will default on their loan\n",
    "- Minimize **false negatives** (predicting a defaulter as a non-defaulter — this leads to NPAs)\n",
    "- Balance between **precision** and **recall** to optimize the lending strategy\n",
    "- Provide actionable insights for credit risk management\n",
    "\n",
    "### Key Business Questions\n",
    "1. How to detect real defaulters while minimizing false positives?\n",
    "2. How to handle the NPA problem by playing safe in loan disbursement?\n",
    "3. Which features most strongly predict loan default?\n",
    "\n",
    "### Target Variable\n",
    "- `loan_status`: \"Fully Paid\" vs \"Charged Off\"\n",
    "  - **Fully Paid (0)** — Borrower successfully repaid the loan\n",
    "  - **Charged Off (1)** — Borrower defaulted on the loan\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:30.018217Z",
     "iopub.status.busy": "2026-02-08T07:17:30.018083Z",
     "iopub.status.idle": "2026-02-08T07:17:31.094388Z",
     "shell.execute_reply": "2026-02-08T07:17:31.093580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Pandas version: 3.0.0\n",
      "NumPy version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score,\n",
    "                             accuracy_score, f1_score, precision_score, recall_score)\n",
    "\n",
    "# Statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "print('All libraries imported successfully!')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.119595Z",
     "iopub.status.busy": "2026-02-08T07:17:31.119384Z",
     "iopub.status.idle": "2026-02-08T07:17:31.169229Z",
     "shell.execute_reply": "2026-02-08T07:17:31.168316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10000, 27)\n",
      "Number of Rows: 10000\n",
      "Number of Columns: 27\n",
      "\n",
      "Memory Usage: 9.31 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/LoanTapData.csv')\n",
    "\n",
    "print(f'Dataset Shape: {df.shape}')\n",
    "print(f'Number of Rows: {df.shape[0]}')\n",
    "print(f'Number of Columns: {df.shape[1]}')\n",
    "print(f'\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.171340Z",
     "iopub.status.busy": "2026-02-08T07:17:31.171192Z",
     "iopub.status.idle": "2026-02-08T07:17:31.184106Z",
     "shell.execute_reply": "2026-02-08T07:17:31.183249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FIRST 5 ROWS OF THE DATASET\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>...</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13254</td>\n",
       "      <td>36 months</td>\n",
       "      <td>27.10</td>\n",
       "      <td>541.81</td>\n",
       "      <td>E</td>\n",
       "      <td>E3</td>\n",
       "      <td>Office Manager</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>95208.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20555.51</td>\n",
       "      <td>17.6</td>\n",
       "      <td>10</td>\n",
       "      <td>f</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4171 River Rd\\nMilwaukee, MI 29621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33863</td>\n",
       "      <td>36 months</td>\n",
       "      <td>28.02</td>\n",
       "      <td>1401.06</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>31527.20</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>9601.47</td>\n",
       "      <td>15.4</td>\n",
       "      <td>42</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8512 Washington Blvd\\nBaltimore, WV 74158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24595</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.23</td>\n",
       "      <td>855.37</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>36749.07</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>9756.61</td>\n",
       "      <td>73.8</td>\n",
       "      <td>42</td>\n",
       "      <td>f</td>\n",
       "      <td>Individual</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2242 Oak Ave\\nLos Angeles, IN 97148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19953</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.09</td>\n",
       "      <td>444.75</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>Manager</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>23455.49</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>15376.83</td>\n",
       "      <td>114.1</td>\n",
       "      <td>25</td>\n",
       "      <td>f</td>\n",
       "      <td>Individual</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7693 Maple Dr\\nSalt Lake City, NH 35205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8608</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.46</td>\n",
       "      <td>267.60</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>Server</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RENT</td>\n",
       "      <td>89482.22</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11092.12</td>\n",
       "      <td>66.6</td>\n",
       "      <td>18</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1403 Cedar Ln\\nCharlotte, WI 81397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term  int_rate  installment grade sub_grade  \\\n",
       "0      13254   36 months     27.10       541.81     E        E3   \n",
       "1      33863   36 months     28.02      1401.06     D        D2   \n",
       "2      24595   36 months     15.23       855.37     C        C4   \n",
       "3      19953   60 months     12.09       444.75     C        C5   \n",
       "4       8608   36 months      7.46       267.60     A        A2   \n",
       "\n",
       "        emp_title emp_length home_ownership  annual_inc  ... open_acc pub_rec  \\\n",
       "0  Office Manager  10+ years           RENT    95208.14  ...        4       1   \n",
       "1  Data Scientist  10+ years       MORTGAGE    31527.20  ...       27       0   \n",
       "2  Data Scientist    5 years       MORTGAGE    36749.07  ...       29       0   \n",
       "3         Manager    4 years           RENT    23455.49  ...       19       0   \n",
       "4          Server        NaN           RENT    89482.22  ...        3       1   \n",
       "\n",
       "  revol_bal revol_util total_acc  initial_list_status application_type  \\\n",
       "0  20555.51       17.6        10                    f       Individual   \n",
       "1   9601.47       15.4        42                    w       Individual   \n",
       "2   9756.61       73.8        42                    f       Individual   \n",
       "3  15376.83      114.1        25                    f       Individual   \n",
       "4  11092.12       66.6        18                    w       Individual   \n",
       "\n",
       "   mort_acc  pub_rec_bankruptcies                                    address  \n",
       "0       0.0                   0.0         4171 River Rd\\nMilwaukee, MI 29621  \n",
       "1       1.0                   1.0  8512 Washington Blvd\\nBaltimore, WV 74158  \n",
       "2       7.0                   0.0        2242 Oak Ave\\nLos Angeles, IN 97148  \n",
       "3       2.0                   0.0    7693 Maple Dr\\nSalt Lake City, NH 35205  \n",
       "4       6.0                   0.0         1403 Cedar Ln\\nCharlotte, WI 81397  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print('='*80)\n",
    "print('FIRST 5 ROWS OF THE DATASET')\n",
    "print('='*80)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.186324Z",
     "iopub.status.busy": "2026-02-08T07:17:31.186210Z",
     "iopub.status.idle": "2026-02-08T07:17:31.195812Z",
     "shell.execute_reply": "2026-02-08T07:17:31.194856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA TYPES & STRUCTURE\n",
      "================================================================================\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   loan_amnt             10000 non-null  int64  \n",
      " 1   term                  10000 non-null  str    \n",
      " 2   int_rate              10000 non-null  float64\n",
      " 3   installment           10000 non-null  float64\n",
      " 4   grade                 10000 non-null  str    \n",
      " 5   sub_grade             10000 non-null  str    \n",
      " 6   emp_title             9701 non-null   str    \n",
      " 7   emp_length            9060 non-null   str    \n",
      " 8   home_ownership        10000 non-null  str    \n",
      " 9   annual_inc            10000 non-null  float64\n",
      " 10  verification_status   10000 non-null  str    \n",
      " 11  issue_d               10000 non-null  str    \n",
      " 12  loan_status           10000 non-null  str    \n",
      " 13  purpose               10000 non-null  str    \n",
      " 14  title                 9800 non-null   str    \n",
      " 15  dti                   10000 non-null  float64\n",
      " 16  earliest_cr_line      10000 non-null  str    \n",
      " 17  open_acc              10000 non-null  int64  \n",
      " 18  pub_rec               10000 non-null  int64  \n",
      " 19  revol_bal             10000 non-null  float64\n",
      " 20  revol_util            9850 non-null   float64\n",
      " 21  total_acc             10000 non-null  int64  \n",
      " 22  initial_list_status   10000 non-null  str    \n",
      " 23  application_type      10000 non-null  str    \n",
      " 24  mort_acc              9700 non-null   float64\n",
      " 25  pub_rec_bankruptcies  9606 non-null   float64\n",
      " 26  address               10000 non-null  str    \n",
      "dtypes: float64(8), int64(4), str(15)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Data types and info\n",
    "print('='*80)\n",
    "print('DATA TYPES & STRUCTURE')\n",
    "print('='*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.197927Z",
     "iopub.status.busy": "2026-02-08T07:17:31.197801Z",
     "iopub.status.idle": "2026-02-08T07:17:31.218559Z",
     "shell.execute_reply": "2026-02-08T07:17:31.217430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL SUMMARY - NUMERICAL FEATURES\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>9850.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>9700.00</td>\n",
       "      <td>9606.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16811.50</td>\n",
       "      <td>17.39</td>\n",
       "      <td>548.75</td>\n",
       "      <td>71410.47</td>\n",
       "      <td>22.84</td>\n",
       "      <td>15.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21279.84</td>\n",
       "      <td>60.61</td>\n",
       "      <td>25.63</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9146.75</td>\n",
       "      <td>7.16</td>\n",
       "      <td>321.84</td>\n",
       "      <td>46341.66</td>\n",
       "      <td>13.00</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.87</td>\n",
       "      <td>24482.81</td>\n",
       "      <td>34.77</td>\n",
       "      <td>9.77</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3017.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>60.72</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>315.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9683.25</td>\n",
       "      <td>11.17</td>\n",
       "      <td>304.25</td>\n",
       "      <td>40037.72</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6725.21</td>\n",
       "      <td>30.02</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15012.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>479.30</td>\n",
       "      <td>59936.24</td>\n",
       "      <td>22.99</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13169.81</td>\n",
       "      <td>61.10</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22654.25</td>\n",
       "      <td>23.45</td>\n",
       "      <td>734.30</td>\n",
       "      <td>89233.60</td>\n",
       "      <td>34.22</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26172.37</td>\n",
       "      <td>90.60</td>\n",
       "      <td>33.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.00</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1694.49</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amnt  int_rate  installment  annual_inc       dti  open_acc  \\\n",
       "count   10000.00  10000.00     10000.00    10000.00  10000.00  10000.00   \n",
       "mean    16811.50     17.39       548.75    71410.47     22.84     15.65   \n",
       "std      9146.75      7.16       321.84    46341.66     13.00      8.12   \n",
       "min      3017.00      5.00        60.72    10000.00      0.00      2.00   \n",
       "25%      9683.25     11.17       304.25    40037.72     11.53      9.00   \n",
       "50%     15012.00     17.39       479.30    59936.24     22.99     16.00   \n",
       "75%     22654.25     23.45       734.30    89233.60     34.22     23.00   \n",
       "max     40000.00     29.99      1694.49   500000.00     45.00     29.00   \n",
       "\n",
       "        pub_rec  revol_bal  revol_util  total_acc  mort_acc  \\\n",
       "count  10000.00   10000.00     9850.00   10000.00   9700.00   \n",
       "mean       0.42   21279.84       60.61      25.63      2.49   \n",
       "std        0.87   24482.81       34.77       9.77      2.44   \n",
       "min        0.00     315.84        0.00       3.00      0.00   \n",
       "25%        0.00    6725.21       30.02      18.00      0.00   \n",
       "50%        0.00   13169.81       61.10      26.00      2.00   \n",
       "75%        0.00   26172.37       90.60      33.00      4.00   \n",
       "max        4.00  200000.00      120.00      48.00     10.00   \n",
       "\n",
       "       pub_rec_bankruptcies  \n",
       "count               9606.00  \n",
       "mean                   0.19  \n",
       "std                    0.53  \n",
       "min                    0.00  \n",
       "25%                    0.00  \n",
       "50%                    0.00  \n",
       "75%                    0.00  \n",
       "max                    3.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical summary for numerical columns\n",
    "print('='*80)\n",
    "print('STATISTICAL SUMMARY - NUMERICAL FEATURES')\n",
    "print('='*80)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.220969Z",
     "iopub.status.busy": "2026-02-08T07:17:31.220814Z",
     "iopub.status.idle": "2026-02-08T07:17:31.249181Z",
     "shell.execute_reply": "2026-02-08T07:17:31.247977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL SUMMARY - CATEGORICAL FEATURES\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>9701</td>\n",
       "      <td>9060</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>9800</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Oct-2019</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>Jan-1999</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>4171 River Rd\\nMilwaukee, MI 29621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6899</td>\n",
       "      <td>2518</td>\n",
       "      <td>535</td>\n",
       "      <td>314</td>\n",
       "      <td>3080</td>\n",
       "      <td>4245</td>\n",
       "      <td>3520</td>\n",
       "      <td>166</td>\n",
       "      <td>8051</td>\n",
       "      <td>3468</td>\n",
       "      <td>3392</td>\n",
       "      <td>51</td>\n",
       "      <td>5517</td>\n",
       "      <td>8479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  grade sub_grade emp_title emp_length home_ownership  \\\n",
       "count        10000  10000     10000      9701       9060          10000   \n",
       "unique           2      7        35        35         11              4   \n",
       "top      36 months      B        B4  Attorney  10+ years       MORTGAGE   \n",
       "freq          6899   2518       535       314       3080           4245   \n",
       "\n",
       "       verification_status   issue_d loan_status             purpose  \\\n",
       "count                10000     10000       10000               10000   \n",
       "unique                   3        72           2                  14   \n",
       "top               Verified  Oct-2019  Fully Paid  debt_consolidation   \n",
       "freq                  3520       166        8051                3468   \n",
       "\n",
       "                     title earliest_cr_line initial_list_status  \\\n",
       "count                 9800            10000               10000   \n",
       "unique                  14              337                   2   \n",
       "top     Debt consolidation         Jan-1999                   w   \n",
       "freq                  3392               51                5517   \n",
       "\n",
       "       application_type                             address  \n",
       "count             10000                               10000  \n",
       "unique                2                               10000  \n",
       "top          Individual  4171 River Rd\\nMilwaukee, MI 29621  \n",
       "freq               8479                                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical summary for categorical columns\n",
    "print('='*80)\n",
    "print('STATISTICAL SUMMARY - CATEGORICAL FEATURES')\n",
    "print('='*80)\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.251689Z",
     "iopub.status.busy": "2026-02-08T07:17:31.251547Z",
     "iopub.status.idle": "2026-02-08T07:17:31.265104Z",
     "shell.execute_reply": "2026-02-08T07:17:31.264081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "                      Missing Count  Missing %\n",
      "emp_length                      940       9.40\n",
      "pub_rec_bankruptcies            394       3.94\n",
      "mort_acc                        300       3.00\n",
      "emp_title                       299       2.99\n",
      "title                           200       2.00\n",
      "revol_util                      150       1.50\n",
      "\n",
      "Total columns with missing values: 6\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print('='*80)\n",
    "print('MISSING VALUES ANALYSIS')\n",
    "print('='*80)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "print(missing_df)\n",
    "print(f'\\nTotal columns with missing values: {len(missing_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.267614Z",
     "iopub.status.busy": "2026-02-08T07:17:31.267478Z",
     "iopub.status.idle": "2026-02-08T07:17:31.396296Z",
     "shell.execute_reply": "2026-02-08T07:17:31.395320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insight: Missing values exist in pub_rec_bankruptcies, mort_acc, title, and revol_util.\n",
      "These need appropriate imputation strategies.\n"
     ]
    }
   ],
   "source": [
    "# Visualize missing values\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "if len(missing_df) > 0:\n",
    "    missing_df['Missing %'].plot(kind='barh', color=sns.color_palette('Reds_r', len(missing_df)), ax=ax)\n",
    "    ax.set_xlabel('Missing Percentage (%)')\n",
    "    ax.set_title('Missing Values by Feature', fontsize=16, fontweight='bold')\n",
    "    for i, v in enumerate(missing_df['Missing %']):\n",
    "        ax.text(v + 0.1, i, f'{v}%', va='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/missing_values.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('\\nInsight: Missing values exist in pub_rec_bankruptcies, mort_acc, title, and revol_util.')\n",
    "print('These need appropriate imputation strategies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.398879Z",
     "iopub.status.busy": "2026-02-08T07:17:31.398708Z",
     "iopub.status.idle": "2026-02-08T07:17:31.411452Z",
     "shell.execute_reply": "2026-02-08T07:17:31.410337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted categorical columns to category dtype.\n",
      "\n",
      "Numerical columns: ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'mort_acc', 'pub_rec_bankruptcies']\n",
      "\n",
      "Categorical columns: ['term', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'loan_status', 'purpose', 'title', 'initial_list_status', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "cat_cols = ['term', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership',\n",
    "            'verification_status', 'loan_status', 'purpose', 'title',\n",
    "            'initial_list_status', 'application_type']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "print('Converted categorical columns to category dtype.')\n",
    "print(f'\\nNumerical columns: {df.select_dtypes(include=[\"number\"]).columns.tolist()}')\n",
    "print(f'\\nCategorical columns: {df.select_dtypes(include=[\"category\"]).columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations on Data Structure:\n",
    "\n",
    "1. **Shape**: The dataset contains 10,000 loan records with 27 features\n",
    "2. **Data Types**: Mix of numerical (float64, int64) and categorical (object) features\n",
    "3. **Missing Values**: Found in `pub_rec_bankruptcies`, `mort_acc`, `title`, `revol_util`, and `emp_title`\n",
    "4. **Target Variable**: `loan_status` is binary (Fully Paid / Charged Off)\n",
    "5. **Range**: Loan amounts range from ~$1,000 to ~$40,000; interest rates from 5% to 30%\n",
    "6. **Outliers**: `annual_inc` and `revol_bal` show high variance with potential outliers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.414063Z",
     "iopub.status.busy": "2026-02-08T07:17:31.413919Z",
     "iopub.status.idle": "2026-02-08T07:17:31.561613Z",
     "shell.execute_reply": "2026-02-08T07:17:31.560357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHT: 80.5% of customers have Fully Paid their loan.\n",
      ">>> The dataset is IMBALANCED with approximately 19.5% defaults (Charged Off).\n",
      ">>> This class imbalance needs to be addressed during model building.\n"
     ]
    }
   ],
   "source": [
    "# TARGET VARIABLE DISTRIBUTION\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "status_counts = df['loan_status'].value_counts()\n",
    "axes[0].bar(status_counts.index.astype(str), status_counts.values, color=colors, edgecolor='black', linewidth=1.2)\n",
    "axes[0].set_title('Loan Status Distribution', fontsize=16, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, (val, count) in enumerate(zip(status_counts.index, status_counts.values)):\n",
    "    axes[0].text(i, count + 50, f'{count}\\n({count/len(df)*100:.1f}%)', ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "axes[1].pie(status_counts.values, labels=status_counts.index.astype(str), autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90, explode=[0, 0.05],\n",
    "            shadow=True, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Loan Status Proportion', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/target_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fully_paid_pct = (df['loan_status'] == 'Fully Paid').sum() / len(df) * 100\n",
    "print(f'\\n>>> INSIGHT: {fully_paid_pct:.1f}% of customers have Fully Paid their loan.')\n",
    "print(f'>>> The dataset is IMBALANCED with approximately {100-fully_paid_pct:.1f}% defaults (Charged Off).')\n",
    "print(f'>>> This class imbalance needs to be addressed during model building.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:31.563894Z",
     "iopub.status.busy": "2026-02-08T07:17:31.563775Z",
     "iopub.status.idle": "2026-02-08T07:17:33.356224Z",
     "shell.execute_reply": "2026-02-08T07:17:33.354973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHTS - Continuous Variables:\n",
      "   1. loan_amnt: Right-skewed distribution; most loans cluster between $5K-$20K\n",
      "   2. int_rate: Roughly uniform distribution between 5-30%\n",
      "   3. annual_inc: Heavily right-skewed with most incomes $30K-$100K\n",
      "   4. dti: Roughly uniform between 0-45\n",
      "   5. revol_bal: Heavily right-skewed with potential outliers at the high end\n",
      "   6. revol_util: Slightly right-skewed with most borrowers utilizing 20-80% of credit\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUTION OF CONTINUOUS VARIABLES\n",
    "continuous_vars = ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti',\n",
    "                   'open_acc', 'revol_bal', 'revol_util', 'total_acc']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(continuous_vars):\n",
    "    ax = axes[i]\n",
    "    data = df[col].dropna()\n",
    "    ax.hist(data, bins=40, color='#3498db', edgecolor='black', alpha=0.7, density=True)\n",
    "    data.plot(kind='kde', ax=ax, color='#e74c3c', linewidth=2)\n",
    "    ax.set_title(f'Distribution of {col}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.axvline(data.mean(), color='green', linestyle='--', linewidth=1.5, label=f'Mean: {data.mean():.1f}')\n",
    "    ax.axvline(data.median(), color='orange', linestyle='--', linewidth=1.5, label=f'Median: {data.median():.1f}')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Distribution of Continuous Variables', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/continuous_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> INSIGHTS - Continuous Variables:')\n",
    "print('   1. loan_amnt: Right-skewed distribution; most loans cluster between $5K-$20K')\n",
    "print('   2. int_rate: Roughly uniform distribution between 5-30%')\n",
    "print('   3. annual_inc: Heavily right-skewed with most incomes $30K-$100K')\n",
    "print('   4. dti: Roughly uniform between 0-45')\n",
    "print('   5. revol_bal: Heavily right-skewed with potential outliers at the high end')\n",
    "print('   6. revol_util: Slightly right-skewed with most borrowers utilizing 20-80% of credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:33.358801Z",
     "iopub.status.busy": "2026-02-08T07:17:33.358643Z",
     "iopub.status.idle": "2026-02-08T07:17:33.953901Z",
     "shell.execute_reply": "2026-02-08T07:17:33.952693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHTS - Categorical Variables:\n",
      "   1. The majority of people have home ownership as: MORTGAGE\n",
      "   2. Grades B and C dominate the portfolio\n",
      "   3. 36-month term is preferred by ~70% of borrowers\n",
      "   4. debt_consolidation is the most common loan purpose\n",
      "   5. ~85% of applications are Individual type\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL VARIABLES - BAR PLOTS\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "grade_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "sns.countplot(data=df, x='grade', order=grade_order, ax=axes[0,0], palette='RdYlGn_r')\n",
    "axes[0,0].set_title('Loan Grade Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Grade')\n",
    "\n",
    "home_order = df['home_ownership'].value_counts().index.tolist()\n",
    "sns.countplot(data=df, x='home_ownership', ax=axes[0,1], palette='Set2', order=home_order)\n",
    "axes[0,1].set_title('Home Ownership Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Home Ownership')\n",
    "\n",
    "sns.countplot(data=df, x='verification_status', ax=axes[0,2], palette='Pastel1')\n",
    "axes[0,2].set_title('Verification Status Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,2].set_xlabel('Verification Status')\n",
    "\n",
    "purpose_counts = df['purpose'].value_counts().head(8)\n",
    "axes[1,0].barh(purpose_counts.index.astype(str), purpose_counts.values, color=sns.color_palette('husl', 8))\n",
    "axes[1,0].set_title('Top 8 Loan Purposes', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Count')\n",
    "\n",
    "sns.countplot(data=df, x='term', ax=axes[1,1], palette='coolwarm')\n",
    "axes[1,1].set_title('Loan Term Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Term')\n",
    "\n",
    "sns.countplot(data=df, x='application_type', ax=axes[1,2], palette='Set3')\n",
    "axes[1,2].set_title('Application Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1,2].set_xlabel('Application Type')\n",
    "\n",
    "plt.suptitle('Distribution of Categorical Variables', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/categorical_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "majority_home = df['home_ownership'].value_counts().index[0]\n",
    "print(f'\\n>>> INSIGHTS - Categorical Variables:')\n",
    "print(f'   1. The majority of people have home ownership as: {majority_home}')\n",
    "print(f'   2. Grades B and C dominate the portfolio')\n",
    "print(f'   3. 36-month term is preferred by ~70% of borrowers')\n",
    "print(f'   4. debt_consolidation is the most common loan purpose')\n",
    "print(f'   5. ~85% of applications are Individual type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:33.956490Z",
     "iopub.status.busy": "2026-02-08T07:17:33.956349Z",
     "iopub.status.idle": "2026-02-08T07:17:34.200403Z",
     "shell.execute_reply": "2026-02-08T07:17:34.199474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Top 2 Most Afforded Job Titles:\n",
      "   1. Attorney: 314 borrowers\n",
      "   2. Data Scientist: 304 borrowers\n",
      "\n",
      ">>> 10+ years of employment is the most common employment length\n"
     ]
    }
   ],
   "source": [
    "# EMPLOYMENT LENGTH & TITLE ANALYSIS\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "emp_order = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years',\n",
    "             '6 years', '7 years', '8 years', '9 years', '10+ years']\n",
    "emp_counts = df['emp_length'].value_counts().reindex(emp_order).dropna()\n",
    "axes[0].bar(range(len(emp_counts)), emp_counts.values, color=sns.color_palette('viridis', len(emp_counts)),\n",
    "            edgecolor='black')\n",
    "axes[0].set_xticks(range(len(emp_counts)))\n",
    "axes[0].set_xticklabels(emp_counts.index, rotation=45, ha='right')\n",
    "axes[0].set_title('Employment Length Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "top_titles = df['emp_title'].value_counts().head(15)\n",
    "axes[1].barh(top_titles.index[::-1].astype(str), top_titles.values[::-1],\n",
    "             color=sns.color_palette('coolwarm', 15))\n",
    "axes[1].set_title('Top 15 Employment Titles', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/employment_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "top_2_titles = df['emp_title'].value_counts().head(2)\n",
    "print(f'\\n>>> Top 2 Most Afforded Job Titles:')\n",
    "for i, (title, count) in enumerate(top_2_titles.items(), 1):\n",
    "    print(f'   {i}. {title}: {count} borrowers')\n",
    "print(f'\\n>>> 10+ years of employment is the most common employment length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:34.202923Z",
     "iopub.status.busy": "2026-02-08T07:17:34.202755Z",
     "iopub.status.idle": "2026-02-08T07:17:34.426766Z",
     "shell.execute_reply": "2026-02-08T07:17:34.425565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHT: Grade A default rate: 16.2% | Grade G default rate: 22.8%\n",
      ">>> People with Grade A are MORE likely to fully pay their loan. (TRUE)\n",
      ">>> There is a CLEAR monotonic relationship: as grade worsens (A to G), default rate increases.\n"
     ]
    }
   ],
   "source": [
    "# LOAN STATUS vs GRADE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ct = pd.crosstab(df['grade'], df['loan_status'], normalize='index') * 100\n",
    "ct = ct.reindex(grade_order)\n",
    "ct.plot(kind='bar', stacked=True, color=colors, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Default Rate by Loan Grade', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_xlabel('Grade')\n",
    "axes[0].legend(title='Loan Status')\n",
    "axes[0].set_xticklabels(grade_order, rotation=0)\n",
    "\n",
    "default_by_grade = df[df['loan_status'] == 'Charged Off'].groupby('grade', observed=False).size() / df.groupby('grade', observed=False).size() * 100\n",
    "default_by_grade = default_by_grade.reindex(grade_order)\n",
    "axes[1].plot(grade_order, default_by_grade.values, 'ro-', linewidth=2, markersize=10)\n",
    "axes[1].fill_between(grade_order, default_by_grade.values, alpha=0.3, color='red')\n",
    "axes[1].set_title('Default Rate (%) by Grade', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Default Rate (%)')\n",
    "axes[1].set_xlabel('Grade')\n",
    "for i, v in enumerate(default_by_grade.values):\n",
    "    axes[1].text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/grade_vs_default.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "grade_a_default = default_by_grade.get('A', 0)\n",
    "grade_g_default = default_by_grade.get('G', 0)\n",
    "print(f'\\n>>> INSIGHT: Grade A default rate: {grade_a_default:.1f}% | Grade G default rate: {grade_g_default:.1f}%')\n",
    "print(f'>>> People with Grade A are MORE likely to fully pay their loan. (TRUE)')\n",
    "print(f'>>> There is a CLEAR monotonic relationship: as grade worsens (A to G), default rate increases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:34.428802Z",
     "iopub.status.busy": "2026-02-08T07:17:34.428695Z",
     "iopub.status.idle": "2026-02-08T07:17:35.003246Z",
     "shell.execute_reply": "2026-02-08T07:17:35.002219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHTS - Bivariate Box Plots:\n",
      "   1. Defaulters tend to have HIGHER interest rates\n",
      "   2. Defaulters tend to have slightly HIGHER loan amounts\n",
      "   3. Annual income shows many outliers but similar medians between groups\n",
      "   4. DTI ratio is slightly higher for defaulters\n",
      "   5. Revolving balance shows significant outliers in both groups\n"
     ]
    }
   ],
   "source": [
    "# LOAN STATUS vs CONTINUOUS VARIABLES - BOX PLOTS\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "box_vars = ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'revol_bal']\n",
    "\n",
    "for i, col in enumerate(box_vars):\n",
    "    row, c = divmod(i, 3)\n",
    "    sns.boxplot(data=df, x='loan_status', y=col, ax=axes[row, c], palette=colors,\n",
    "                order=['Fully Paid', 'Charged Off'])\n",
    "    axes[row, c].set_title(f'{col} by Loan Status', fontsize=13, fontweight='bold')\n",
    "    axes[row, c].set_xlabel('Loan Status')\n",
    "\n",
    "plt.suptitle('Box Plots: Continuous Variables vs Loan Status', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/boxplots_vs_status.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> INSIGHTS - Bivariate Box Plots:')\n",
    "print('   1. Defaulters tend to have HIGHER interest rates')\n",
    "print('   2. Defaulters tend to have slightly HIGHER loan amounts')\n",
    "print('   3. Annual income shows many outliers but similar medians between groups')\n",
    "print('   4. DTI ratio is slightly higher for defaulters')\n",
    "print('   5. Revolving balance shows significant outliers in both groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:35.005709Z",
     "iopub.status.busy": "2026-02-08T07:17:35.005566Z",
     "iopub.status.idle": "2026-02-08T07:17:35.313046Z",
     "shell.execute_reply": "2026-02-08T07:17:35.311805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHTS:\n",
      "   1. Home ownership type has moderate influence on default rates\n",
      "   2. Small business loans tend to have higher default rates\n",
      "   3. Debt consolidation and credit card purposes have moderate default rates\n"
     ]
    }
   ],
   "source": [
    "# LOAN STATUS vs HOME OWNERSHIP & PURPOSE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "ct_home = pd.crosstab(df['home_ownership'], df['loan_status'], normalize='index') * 100\n",
    "ct_home.plot(kind='bar', color=colors, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Default Rate by Home Ownership', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].legend(title='Loan Status')\n",
    "\n",
    "top_purposes = df['purpose'].value_counts().head(8).index\n",
    "df_top_purpose = df[df['purpose'].isin(top_purposes)]\n",
    "ct_purpose = pd.crosstab(df_top_purpose['purpose'], df_top_purpose['loan_status'], normalize='index') * 100\n",
    "ct_purpose = ct_purpose.sort_values('Charged Off', ascending=True)\n",
    "ct_purpose.plot(kind='barh', stacked=True, color=colors, ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('Default Rate by Loan Purpose', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Percentage (%)')\n",
    "axes[1].legend(title='Loan Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/categorical_vs_status.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> INSIGHTS:')\n",
    "print('   1. Home ownership type has moderate influence on default rates')\n",
    "print('   2. Small business loans tend to have higher default rates')\n",
    "print('   3. Debt consolidation and credit card purposes have moderate default rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:35.315538Z",
     "iopub.status.busy": "2026-02-08T07:17:35.315398Z",
     "iopub.status.idle": "2026-02-08T07:17:35.534730Z",
     "shell.execute_reply": "2026-02-08T07:17:35.533534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHTS:\n",
      "   1. 60-month loans have a HIGHER default rate than 36-month loans\n",
      "   2. Verification status shows slight variation in default rates\n"
     ]
    }
   ],
   "source": [
    "# LOAN STATUS vs TERM & VERIFICATION STATUS\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ct_term = pd.crosstab(df['term'], df['loan_status'], normalize='index') * 100\n",
    "ct_term.plot(kind='bar', color=colors, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Default Rate by Loan Term', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].legend(title='Loan Status')\n",
    "\n",
    "ct_verify = pd.crosstab(df['verification_status'], df['loan_status'], normalize='index') * 100\n",
    "ct_verify.plot(kind='bar', color=colors, ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('Default Rate by Verification Status', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "axes[1].legend(title='Loan Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/term_verification_vs_status.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> INSIGHTS:')\n",
    "print('   1. 60-month loans have a HIGHER default rate than 36-month loans')\n",
    "print('   2. Verification status shows slight variation in default rates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:35.537253Z",
     "iopub.status.busy": "2026-02-08T07:17:35.537109Z",
     "iopub.status.idle": "2026-02-08T07:17:35.790948Z",
     "shell.execute_reply": "2026-02-08T07:17:35.790159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> HIGHLY CORRELATED PAIRS (|r| > 0.5):\n",
      "   loan_amnt <-> installment: r = 0.928\n",
      "   open_acc <-> total_acc: r = 0.829\n",
      "\n",
      ">>> INSIGHT: loan_amnt and installment have a very HIGH positive correlation.\n",
      "   This is expected as installment is directly computed from loan amount and interest rate.\n",
      "   We may need to consider dropping one of them to avoid multicollinearity.\n"
     ]
    }
   ],
   "source": [
    "# CORRELATION HEATMAP\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, square=True, linewidths=0.5, ax=ax,\n",
    "            cbar_kws={'shrink': 0.8, 'label': 'Correlation Coefficient'})\n",
    "ax.set_title('Correlation Heatmap - Numerical Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> HIGHLY CORRELATED PAIRS (|r| > 0.5):')\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.5:\n",
    "            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "for c1, c2, r in sorted(high_corr, key=lambda x: abs(x[2]), reverse=True):\n",
    "    print(f'   {c1} <-> {c2}: r = {r:.3f}')\n",
    "\n",
    "print('\\n>>> INSIGHT: loan_amnt and installment have a very HIGH positive correlation.')\n",
    "print('   This is expected as installment is directly computed from loan amount and interest rate.')\n",
    "print('   We may need to consider dropping one of them to avoid multicollinearity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:35.793511Z",
     "iopub.status.busy": "2026-02-08T07:17:35.793368Z",
     "iopub.status.idle": "2026-02-08T07:17:36.392178Z",
     "shell.execute_reply": "2026-02-08T07:17:36.391375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Correlation between Loan Amount and Installment: 0.9279\n",
      ">>> INSIGHT: There is a STRONG POSITIVE correlation between Loan Amount and Installment.\n",
      "   This makes financial sense - higher loan amounts lead to higher monthly installments.\n"
     ]
    }
   ],
   "source": [
    "# SCATTER PLOT: LOAN AMOUNT vs INSTALLMENT\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "scatter = axes[0].scatter(df['loan_amnt'], df['installment'],\n",
    "                           c=df['int_rate'], cmap='RdYlGn_r', alpha=0.5, s=10)\n",
    "axes[0].set_xlabel('Loan Amount ($)')\n",
    "axes[0].set_ylabel('Installment ($)')\n",
    "axes[0].set_title('Loan Amount vs Installment\\n(colored by Interest Rate)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=axes[0], label='Interest Rate (%)')\n",
    "\n",
    "color_map = {'Fully Paid': '#2ecc71', 'Charged Off': '#e74c3c'}\n",
    "for status in ['Fully Paid', 'Charged Off']:\n",
    "    mask = df['loan_status'] == status\n",
    "    axes[1].scatter(df.loc[mask, 'annual_inc'], df.loc[mask, 'loan_amnt'],\n",
    "                    alpha=0.3, s=10, label=status, color=color_map[status])\n",
    "axes[1].set_xlabel('Annual Income ($)')\n",
    "axes[1].set_ylabel('Loan Amount ($)')\n",
    "axes[1].set_title('Annual Income vs Loan Amount\\n(colored by Loan Status)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlim(0, 300000)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/scatter_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "corr_loan_inst = df['loan_amnt'].corr(df['installment'])\n",
    "print(f'\\n>>> Correlation between Loan Amount and Installment: {corr_loan_inst:.4f}')\n",
    "print(f'>>> INSIGHT: There is a STRONG POSITIVE correlation between Loan Amount and Installment.')\n",
    "print(f'   This makes financial sense - higher loan amounts lead to higher monthly installments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Summary\n",
    "\n",
    "| Finding | Detail |\n",
    "|---------|--------|\n",
    "| **Class Imbalance** | ~80% Fully Paid, ~20% Charged Off |\n",
    "| **Key Predictors** | Interest rate, Grade, Term, DTI |\n",
    "| **High Correlation** | loan_amnt <-> installment (r > 0.9) |\n",
    "| **Outliers Present** | annual_inc, revol_bal |\n",
    "| **Missing Values** | pub_rec_bankruptcies, mort_acc, title, revol_util |\n",
    "| **Grade Effect** | Clear monotonic increase in default rate from A to G |\n",
    "| **Term Effect** | 60-month loans default more than 36-month loans |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4. Data Preprocessing\n",
    "\n",
    "### 4.1 Duplicate & Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.394732Z",
     "iopub.status.busy": "2026-02-08T07:17:36.394633Z",
     "iopub.status.idle": "2026-02-08T07:17:36.404944Z",
     "shell.execute_reply": "2026-02-08T07:17:36.403290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "No duplicates found. Data is clean in this regard.\n"
     ]
    }
   ],
   "source": [
    "# DUPLICATE CHECK\n",
    "df_clean = df.copy()\n",
    "\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f'Number of duplicate rows: {duplicates}')\n",
    "\n",
    "if duplicates > 0:\n",
    "    df_clean.drop_duplicates(inplace=True)\n",
    "    print(f'Duplicates removed. New shape: {df_clean.shape}')\n",
    "else:\n",
    "    print('No duplicates found. Data is clean in this regard.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.407320Z",
     "iopub.status.busy": "2026-02-08T07:17:36.407184Z",
     "iopub.status.idle": "2026-02-08T07:17:36.419890Z",
     "shell.execute_reply": "2026-02-08T07:17:36.418899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Before Treatment:\n",
      "emp_title               299\n",
      "emp_length              940\n",
      "title                   200\n",
      "revol_util              150\n",
      "mort_acc                300\n",
      "pub_rec_bankruptcies    394\n",
      "dtype: int64\n",
      "\n",
      ">>> Dropped emp_title (high cardinality, limited predictive power)\n",
      ">>> Filled emp_length missing values with mode: 10+ years\n",
      ">>> Dropped title (redundant with purpose column)\n",
      ">>> Filled revol_util missing values with median: 61.1\n",
      ">>> Filled mort_acc missing values with median: 2.0\n",
      ">>> Filled pub_rec_bankruptcies missing values with 0\n",
      "\n",
      "Missing Values After Treatment:\n",
      "No missing values remain!\n"
     ]
    }
   ],
   "source": [
    "# MISSING VALUE TREATMENT\n",
    "print('Missing Values Before Treatment:')\n",
    "print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])\n",
    "print()\n",
    "\n",
    "# 1. emp_title - Drop (too many unique values, not useful for modeling)\n",
    "df_clean.drop('emp_title', axis=1, inplace=True)\n",
    "print('>>> Dropped emp_title (high cardinality, limited predictive power)')\n",
    "\n",
    "# 2. emp_length - Fill with mode\n",
    "mode_val = df_clean['emp_length'].mode()[0]\n",
    "df_clean['emp_length'] = df_clean['emp_length'].fillna(mode_val)\n",
    "print(f'>>> Filled emp_length missing values with mode: {mode_val}')\n",
    "\n",
    "# 3. title - Drop (redundant with purpose)\n",
    "df_clean.drop('title', axis=1, inplace=True)\n",
    "print('>>> Dropped title (redundant with purpose column)')\n",
    "\n",
    "# 4. revol_util - Fill with median\n",
    "revol_util_median = df_clean['revol_util'].median()\n",
    "df_clean['revol_util'] = df_clean['revol_util'].fillna(revol_util_median)\n",
    "print(f'>>> Filled revol_util missing values with median: {revol_util_median:.1f}')\n",
    "\n",
    "# 5. mort_acc - Fill with median\n",
    "mort_acc_median = df_clean['mort_acc'].median()\n",
    "df_clean['mort_acc'] = df_clean['mort_acc'].fillna(mort_acc_median)\n",
    "print(f'>>> Filled mort_acc missing values with median: {mort_acc_median}')\n",
    "\n",
    "# 6. pub_rec_bankruptcies - Fill with 0 (most common value)\n",
    "df_clean['pub_rec_bankruptcies'] = df_clean['pub_rec_bankruptcies'].fillna(0)\n",
    "print('>>> Filled pub_rec_bankruptcies missing values with 0')\n",
    "\n",
    "print(f'\\nMissing Values After Treatment:')\n",
    "remaining_missing = df_clean.isnull().sum()[df_clean.isnull().sum() > 0]\n",
    "if len(remaining_missing) == 0:\n",
    "    print('No missing values remain!')\n",
    "else:\n",
    "    print(remaining_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.422539Z",
     "iopub.status.busy": "2026-02-08T07:17:36.422398Z",
     "iopub.status.idle": "2026-02-08T07:17:36.739742Z",
     "shell.execute_reply": "2026-02-08T07:17:36.738458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Treatment - IQR Capping Method:\n",
      "   annual_inc: Capped 454 outliers | Range: [-33756, 163027]\n",
      "   revol_bal: Capped 751 outliers | Range: [-22446, 55343]\n",
      "   open_acc: Capped 0 outliers | Range: [-12, 44]\n",
      "   total_acc: Capped 0 outliers | Range: [-4, 56]\n",
      "   dti: Capped 0 outliers | Range: [-23, 68]\n",
      "\n",
      "Dataset shape after outlier treatment: (10000, 25)\n"
     ]
    }
   ],
   "source": [
    "# OUTLIER DETECTION & TREATMENT\n",
    "outlier_cols = ['annual_inc', 'revol_bal', 'open_acc', 'total_acc', 'dti']\n",
    "\n",
    "fig, axes = plt.subplots(1, len(outlier_cols), figsize=(20, 5))\n",
    "\n",
    "for i, col in enumerate(outlier_cols):\n",
    "    axes[i].boxplot(df_clean[col].dropna(), vert=True)\n",
    "    axes[i].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = ((df_clean[col] < lower) | (df_clean[col] > upper)).sum()\n",
    "    axes[i].set_xlabel(f'Outliers: {outliers}', fontsize=10)\n",
    "\n",
    "plt.suptitle('Outlier Detection - Box Plots (Before Treatment)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/outliers_before.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Capping outliers using IQR method\n",
    "print('\\nOutlier Treatment - IQR Capping Method:')\n",
    "for col in outlier_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers_count = ((df_clean[col] < lower) | (df_clean[col] > upper)).sum()\n",
    "    df_clean[col] = df_clean[col].clip(lower=lower, upper=upper)\n",
    "    print(f'   {col}: Capped {outliers_count} outliers | Range: [{lower:.0f}, {upper:.0f}]')\n",
    "\n",
    "print(f'\\nDataset shape after outlier treatment: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.742378Z",
     "iopub.status.busy": "2026-02-08T07:17:36.742240Z",
     "iopub.status.idle": "2026-02-08T07:17:36.766214Z",
     "shell.execute_reply": "2026-02-08T07:17:36.764969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Steps:\n",
      "============================================================\n",
      "1. Created pub_rec_flag (1 if pub_rec > 0):\n",
      "   Distribution: {0: 7545, 1: 2455}\n",
      "\n",
      "2. Created mort_acc_flag (1 if mort_acc > 0):\n",
      "   Distribution: {1: 7560, 0: 2440}\n",
      "\n",
      "3. Created pub_rec_bankruptcies_flag (1 if pub_rec_bankruptcies > 0):\n",
      "   Distribution: {0: 8633, 1: 1367}\n",
      "\n",
      "4. Extracted state from address. Unique states: 50\n",
      "\n",
      "5. Converted term to numeric: [np.float64(36.0), np.float64(60.0)]\n",
      "\n",
      "6. Converted emp_length to numeric (NaN filled with median=5.0)\n",
      "\n",
      "7. Encoded target: Charged Off = 1, Fully Paid = 0\n",
      "   Target distribution: {0: 8051, 1: 1949}\n",
      "\n",
      "8. Created log-transformed features for annual_inc and revol_bal\n",
      "\n",
      "Final shape after feature engineering: (10000, 34)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING\n",
    "print('Feature Engineering Steps:')\n",
    "print('='*60)\n",
    "\n",
    "# 1. Create Flag Variables\n",
    "df_clean['pub_rec_flag'] = (df_clean['pub_rec'] > 0).astype(int)\n",
    "print(f'1. Created pub_rec_flag (1 if pub_rec > 0):')\n",
    "print(f'   Distribution: {df_clean[\"pub_rec_flag\"].value_counts().to_dict()}')\n",
    "\n",
    "df_clean['mort_acc_flag'] = (df_clean['mort_acc'] > 0).astype(int)\n",
    "print(f'\\n2. Created mort_acc_flag (1 if mort_acc > 0):')\n",
    "print(f'   Distribution: {df_clean[\"mort_acc_flag\"].value_counts().to_dict()}')\n",
    "\n",
    "df_clean['pub_rec_bankruptcies_flag'] = (df_clean['pub_rec_bankruptcies'] > 0).astype(int)\n",
    "print(f'\\n3. Created pub_rec_bankruptcies_flag (1 if pub_rec_bankruptcies > 0):')\n",
    "print(f'   Distribution: {df_clean[\"pub_rec_bankruptcies_flag\"].value_counts().to_dict()}')\n",
    "\n",
    "# 2. Extract state from address\n",
    "df_clean['state'] = df_clean['address'].apply(lambda x: str(x).split()[-2] if pd.notna(x) else 'Unknown')\n",
    "print(f'\\n4. Extracted state from address. Unique states: {df_clean[\"state\"].nunique()}')\n",
    "\n",
    "# 3. Convert term to numeric\n",
    "df_clean['term_numeric'] = df_clean['term'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
    "print(f'\\n5. Converted term to numeric: {sorted(df_clean[\"term_numeric\"].unique())}')\n",
    "\n",
    "# 4. Convert emp_length to numeric\n",
    "emp_length_map = {\n",
    "    '< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,\n",
    "    '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9,\n",
    "    '10+ years': 10\n",
    "}\n",
    "df_clean['emp_length_numeric'] = df_clean['emp_length'].astype(str).map(emp_length_map)\n",
    "df_clean['emp_length_numeric'] = df_clean['emp_length_numeric'].fillna(5.0)\n",
    "print(f'\\n6. Converted emp_length to numeric (NaN filled with median=5.0)')\n",
    "\n",
    "# 5. Encode target variable\n",
    "df_clean['target'] = (df_clean['loan_status'] == 'Charged Off').astype(int)\n",
    "print(f'\\n7. Encoded target: Charged Off = 1, Fully Paid = 0')\n",
    "print(f'   Target distribution: {df_clean[\"target\"].value_counts().to_dict()}')\n",
    "\n",
    "# 6. Log transform for skewed features\n",
    "df_clean['log_annual_inc'] = np.log1p(df_clean['annual_inc'])\n",
    "df_clean['log_revol_bal'] = np.log1p(df_clean['revol_bal'])\n",
    "print(f'\\n8. Created log-transformed features for annual_inc and revol_bal')\n",
    "\n",
    "print(f'\\nFinal shape after feature engineering: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Data Preparation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.768616Z",
     "iopub.status.busy": "2026-02-08T07:17:36.768482Z",
     "iopub.status.idle": "2026-02-08T07:17:36.773069Z",
     "shell.execute_reply": "2026-02-08T07:17:36.771768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping: ['loan_amnt', 'int_rate', 'installment', 'grade', 'home_ownership', 'verification_status', 'purpose', 'dti', 'open_acc', 'revol_util', 'total_acc', 'initial_list_status', 'application_type', 'pub_rec_flag', 'mort_acc_flag', 'pub_rec_bankruptcies_flag', 'state', 'term_numeric', 'emp_length_numeric', 'target', 'log_annual_inc', 'log_revol_bal']\n",
      "Shape: (10000, 22)\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA FOR MODELING\n",
    "drop_cols = ['loan_status', 'address', 'issue_d', 'earliest_cr_line', 'term',\n",
    "             'emp_length', 'sub_grade', 'annual_inc', 'revol_bal', 'pub_rec',\n",
    "             'mort_acc', 'pub_rec_bankruptcies']\n",
    "\n",
    "df_model = df_clean.drop(columns=drop_cols, errors='ignore')\n",
    "print(f'Columns after dropping: {df_model.columns.tolist()}')\n",
    "print(f'Shape: {df_model.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.775562Z",
     "iopub.status.busy": "2026-02-08T07:17:36.775424Z",
     "iopub.status.idle": "2026-02-08T07:17:36.784399Z",
     "shell.execute_reply": "2026-02-08T07:17:36.783666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to encode: ['grade', 'home_ownership', 'verification_status', 'purpose', 'initial_list_status', 'application_type', 'state']\n",
      "\n",
      "Shape after one-hot encoding: (10000, 90)\n",
      "Any NaN remaining: False\n",
      "\n",
      "All features (90 total): ['loan_amnt', 'int_rate', 'installment', 'dti', 'open_acc', 'revol_util', 'total_acc', 'pub_rec_flag', 'mort_acc_flag', 'pub_rec_bankruptcies_flag', 'term_numeric', 'emp_length_numeric', 'target', 'log_annual_inc', 'log_revol_bal', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F']...\n"
     ]
    }
   ],
   "source": [
    "# ONE-HOT ENCODING FOR CATEGORICAL VARIABLES\n",
    "cat_features = df_model.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "print(f'Categorical features to encode: {cat_features}')\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=cat_features, drop_first=True, dtype=int)\n",
    "\n",
    "# Fill any remaining NaN values with 0\n",
    "df_model = df_model.fillna(0)\n",
    "\n",
    "print(f'\\nShape after one-hot encoding: {df_model.shape}')\n",
    "print(f'Any NaN remaining: {df_model.isnull().any().any()}')\n",
    "print(f'\\nAll features ({len(df_model.columns)} total): {df_model.columns.tolist()[:20]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.787087Z",
     "iopub.status.busy": "2026-02-08T07:17:36.786949Z",
     "iopub.status.idle": "2026-02-08T07:17:36.796858Z",
     "shell.execute_reply": "2026-02-08T07:17:36.795879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (10000, 89)\n",
      "Target shape: (10000,)\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    8051\n",
      "1    1949\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Default rate: 19.49%\n",
      "\n",
      "Training set: 8000 samples\n",
      "Testing set: 2000 samples\n",
      "\n",
      "Training target distribution: {0: 6441, 1: 1559}\n",
      "Testing target distribution: {0: 1610, 1: 390}\n"
     ]
    }
   ],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "X = df_model.drop('target', axis=1)\n",
    "y = df_model['target']\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(y.value_counts())\n",
    "print(f'\\nDefault rate: {y.mean()*100:.2f}%')\n",
    "\n",
    "# Stratified split to maintain class proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "print(f'\\nTraining set: {X_train.shape[0]} samples')\n",
    "print(f'Testing set: {X_test.shape[0]} samples')\n",
    "print(f'\\nTraining target distribution: {y_train.value_counts().to_dict()}')\n",
    "print(f'Testing target distribution: {y_test.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.799506Z",
     "iopub.status.busy": "2026-02-08T07:17:36.799369Z",
     "iopub.status.idle": "2026-02-08T07:17:36.889674Z",
     "shell.execute_reply": "2026-02-08T07:17:36.888708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling Applied - StandardScaler\n",
      "\n",
      "Scaled Training Data Statistics:\n",
      "       loan_amnt  int_rate  installment     dti  open_acc  revol_util  \\\n",
      "count     8000.0    8000.0       8000.0  8000.0    8000.0      8000.0   \n",
      "mean         0.0      -0.0          0.0     0.0       0.0         0.0   \n",
      "std          1.0       1.0          1.0     1.0       1.0         1.0   \n",
      "\n",
      "       total_acc  pub_rec_flag  mort_acc_flag  pub_rec_bankruptcies_flag  ...  \\\n",
      "count     8000.0        8000.0         8000.0                     8000.0  ...   \n",
      "mean         0.0          -0.0            0.0                       -0.0  ...   \n",
      "std          1.0           1.0            1.0                        1.0  ...   \n",
      "\n",
      "       state_SD  state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  \\\n",
      "count    8000.0    8000.0    8000.0    8000.0    8000.0    8000.0    8000.0   \n",
      "mean        0.0      -0.0       0.0      -0.0       0.0       0.0      -0.0   \n",
      "std         1.0       1.0       1.0       1.0       1.0       1.0       1.0   \n",
      "\n",
      "       state_WI  state_WV  state_WY  \n",
      "count    8000.0    8000.0    8000.0  \n",
      "mean       -0.0      -0.0      -0.0  \n",
      "std         1.0       1.0       1.0  \n",
      "\n",
      "[3 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SCALING - StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for interpretability\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Verify no NaN\n",
    "assert not X_train_scaled.isnull().any().any(), 'NaN found in training data!'\n",
    "assert not X_test_scaled.isnull().any().any(), 'NaN found in test data!'\n",
    "\n",
    "print('Feature Scaling Applied - StandardScaler')\n",
    "print(f'\\nScaled Training Data Statistics:')\n",
    "print(X_train_scaled.describe().round(3).iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='5'></a>\n",
    "## 5. Model Building - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:36.892195Z",
     "iopub.status.busy": "2026-02-08T07:17:36.892054Z",
     "iopub.status.idle": "2026-02-08T07:17:37.840157Z",
     "shell.execute_reply": "2026-02-08T07:17:37.839797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOGISTIC REGRESSION MODEL BUILDING\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.6089 (60.89%)\n",
      "Testing Accuracy:  0.5895 (58.95%)\n",
      "\n",
      "Difference: 1.94%\n",
      ">>> Model shows GOOD generalization (no significant overfitting)\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION MODEL - SKLEARN\n",
    "print('='*80)\n",
    "print('LOGISTIC REGRESSION MODEL BUILDING')\n",
    "print('='*80)\n",
    "\n",
    "# Build model with class_weight='balanced' to handle class imbalance\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    class_weight='balanced',\n",
    "    solver='lbfgs',\n",
    "    random_state=42,\n",
    "    C=1.0\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Training & Test accuracy\n",
    "train_acc = log_reg.score(X_train_scaled, y_train)\n",
    "test_acc = log_reg.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f'\\nTraining Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)')\n",
    "print(f'Testing Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)')\n",
    "print(f'\\nDifference: {abs(train_acc - test_acc)*100:.2f}%')\n",
    "if abs(train_acc - test_acc) < 0.05:\n",
    "    print('>>> Model shows GOOD generalization (no significant overfitting)')\n",
    "else:\n",
    "    print('>>> Model may show signs of overfitting - further investigation needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:37.842050Z",
     "iopub.status.busy": "2026-02-08T07:17:37.841909Z",
     "iopub.status.idle": "2026-02-08T07:17:38.084508Z",
     "shell.execute_reply": "2026-02-08T07:17:38.083222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL COEFFICIENTS\n",
      "================================================================================\n",
      "\n",
      "Intercept: -0.1044\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "                   Feature  Coefficient  Abs_Coefficient  Odds_Ratio\n",
      "                  int_rate     0.542742         0.542742    1.720719\n",
      "       purpose_credit_card    -0.157999         0.157999    0.853850\n",
      "  purpose_home_improvement    -0.137023         0.137023    0.871950\n",
      "purpose_debt_consolidation    -0.136922         0.136922    0.872038\n",
      "                   grade_D     0.126057         0.126057    1.134347\n",
      "                  state_WI    -0.118784         0.118784    0.887999\n",
      "    purpose_major_purchase    -0.111924         0.111924    0.894113\n",
      "               installment    -0.094248         0.094248    0.910057\n",
      "                  state_IL    -0.092128         0.092128    0.911989\n",
      "                   grade_B     0.082470         0.082470    1.085966\n",
      "                  state_PA    -0.081494         0.081494    0.921738\n",
      "                   grade_G     0.081348         0.081348    1.084748\n",
      "                   grade_C     0.080500         0.080500    1.083829\n",
      "                  state_KS    -0.079386         0.079386    0.923683\n",
      "                   grade_F     0.076796         0.076796    1.079821\n",
      "                  state_CO    -0.074552         0.074552    0.928159\n",
      "                   grade_E     0.073508         0.073508    1.076277\n",
      "                  state_WV    -0.071597         0.071597    0.930906\n",
      "            log_annual_inc     0.067478         0.067478    1.069806\n",
      "                 loan_amnt     0.066129         0.066129    1.068365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INSIGHT: Red bars indicate features that INCREASE default risk.\n",
      ">>> Green bars indicate features that DECREASE default risk.\n"
     ]
    }
   ],
   "source": [
    "# MODEL COEFFICIENTS\n",
    "print('='*80)\n",
    "print('MODEL COEFFICIENTS')\n",
    "print('='*80)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': log_reg.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(log_reg.coef_[0]),\n",
    "    'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f'\\nIntercept: {log_reg.intercept_[0]:.4f}')\n",
    "print(f'\\nTop 20 Most Important Features:')\n",
    "print(coef_df.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize top coefficients\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_features = coef_df.head(20)\n",
    "colors_coef = ['#e74c3c' if c > 0 else '#2ecc71' for c in top_features['Coefficient']]\n",
    "ax.barh(range(len(top_features)), top_features['Coefficient'].values, color=colors_coef, edgecolor='black')\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Feature'].values)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_title('Top 20 Logistic Regression Coefficients', fontsize=16, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linewidth=0.8)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#e74c3c', label='Increases Default Risk'),\n",
    "                   Patch(facecolor='#2ecc71', label='Decreases Default Risk')]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/model_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n>>> INSIGHT: Red bars indicate features that INCREASE default risk.')\n",
    "print('>>> Green bars indicate features that DECREASE default risk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:38.087225Z",
     "iopub.status.busy": "2026-02-08T07:17:38.087076Z",
     "iopub.status.idle": "2026-02-08T07:17:38.204436Z",
     "shell.execute_reply": "2026-02-08T07:17:38.203529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATSMODELS LOGISTIC REGRESSION SUMMARY\n",
      "================================================================================\n",
      "                                   Results: Logit\n",
      "====================================================================================\n",
      "Model:                     Logit                  Method:                 MLE       \n",
      "Dependent Variable:        target                 Pseudo R-squared:       0.051     \n",
      "Date:                      2026-02-08 07:17       AIC:                    7671.8370 \n",
      "No. Observations:          8000                   BIC:                    8300.6847 \n",
      "Df Model:                  89                     Log-Likelihood:         -3745.9   \n",
      "Df Residuals:              7910                   LL-Null:                -3945.7   \n",
      "Converged:                 1.0000                 LLR p-value:            6.4187e-41\n",
      "No. Iterations:            6.0000                 Scale:                  1.0000    \n",
      "------------------------------------------------------------------------------------\n",
      "                                     Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                               -1.5208   0.0308 -49.4558 0.0000 -1.5810 -1.4605\n",
      "loan_amnt                            0.0909   0.1631   0.5573 0.5773 -0.2288  0.4106\n",
      "int_rate                             0.5333   0.0445  11.9704 0.0000  0.4460  0.6206\n",
      "installment                         -0.1151   0.1670  -0.6891 0.4907 -0.4425  0.2123\n",
      "dti                                  0.0227   0.0291   0.7804 0.4351 -0.0343  0.0798\n",
      "open_acc                             0.0443   0.0522   0.8484 0.3962 -0.0581  0.1467\n",
      "revol_util                          -0.0139   0.0291  -0.4786 0.6322 -0.0709  0.0431\n",
      "total_acc                            0.0089   0.0523   0.1701 0.8650 -0.0936  0.1114\n",
      "pub_rec_flag                         0.0109   0.0291   0.3753 0.7074 -0.0461  0.0680\n",
      "mort_acc_flag                        0.0027   0.0293   0.0934 0.9256 -0.0546  0.0601\n",
      "pub_rec_bankruptcies_flag            0.0263   0.0287   0.9171 0.3591 -0.0299  0.0826\n",
      "term_numeric                        -0.0745   0.0525  -1.4198 0.1557 -0.1773  0.0283\n",
      "emp_length_numeric                  -0.0094   0.0292  -0.3221 0.7474 -0.0666  0.0478\n",
      "log_annual_inc                       0.0603   0.0293   2.0609 0.0393  0.0030  0.1177\n",
      "log_revol_bal                        0.0210   0.0292   0.7192 0.4720 -0.0362  0.0781\n",
      "grade_B                              0.0854   0.0430   1.9874 0.0469  0.0012  0.1696\n",
      "grade_C                              0.0777   0.0429   1.8108 0.0702 -0.0064  0.1618\n",
      "grade_D                              0.1282   0.0384   3.3359 0.0009  0.0529  0.2035\n",
      "grade_E                              0.0725   0.0363   1.9960 0.0459  0.0013  0.1436\n",
      "grade_F                              0.0749   0.0332   2.2560 0.0241  0.0098  0.1399\n",
      "grade_G                              0.0854   0.0313   2.7296 0.0063  0.0241  0.1467\n",
      "home_ownership_OTHER                 0.0222   0.0288   0.7719 0.4402 -0.0342  0.0787\n",
      "home_ownership_OWN                   0.0057   0.0315   0.1795 0.8576 -0.0561  0.0674\n",
      "home_ownership_RENT                  0.0181   0.0316   0.5717 0.5675 -0.0439  0.0800\n",
      "verification_status_Source Verified -0.0505   0.0335  -1.5050 0.1323 -0.1162  0.0153\n",
      "verification_status_Verified        -0.0198   0.0331  -0.5975 0.5502 -0.0847  0.0451\n",
      "purpose_credit_card                 -0.1636   0.0653  -2.5044 0.0123 -0.2916 -0.0356\n",
      "purpose_debt_consolidation          -0.1274   0.0739  -1.7239 0.0847 -0.2722  0.0174\n",
      "purpose_educational                 -0.0496   0.0337  -1.4729 0.1408 -0.1157  0.0164\n",
      "purpose_home_improvement            -0.1401   0.0524  -2.6734 0.0075 -0.2428 -0.0374\n",
      "purpose_house                       -0.0542   0.0352  -1.5418 0.1231 -0.1231  0.0147\n",
      "purpose_major_purchase              -0.1087   0.0458  -2.3725 0.0177 -0.1985 -0.0189\n",
      "purpose_medical                     -0.0590   0.0401  -1.4713 0.1412 -0.1375  0.0196\n",
      "purpose_moving                      -0.0048   0.0338  -0.1424 0.8868 -0.0711  0.0615\n",
      "purpose_other                       -0.0203   0.0472  -0.4305 0.6669 -0.1128  0.0722\n",
      "purpose_renewable_energy            -0.0247   0.0327  -0.7564 0.4494 -0.0888  0.0393\n",
      "purpose_small_business              -0.0545   0.0405  -1.3444 0.1788 -0.1340  0.0250\n",
      "purpose_vacation                    -0.0276   0.0344  -0.8027 0.4221 -0.0951  0.0398\n",
      "purpose_wedding                     -0.0450   0.0363  -1.2412 0.2145 -0.1162  0.0261\n",
      "initial_list_status_w               -0.0036   0.0292  -0.1233 0.9019 -0.0607  0.0535\n",
      "application_type_Joint App          -0.0123   0.0295  -0.4161 0.6773 -0.0700  0.0455\n",
      "state_AL                            -0.0164   0.0375  -0.4370 0.6621 -0.0898  0.0571\n",
      "state_AR                            -0.0287   0.0388  -0.7390 0.4599 -0.1047  0.0474\n",
      "state_AZ                            -0.0345   0.0385  -0.8951 0.3707 -0.1099  0.0410\n",
      "state_CA                            -0.0179   0.0398  -0.4503 0.6525 -0.0958  0.0600\n",
      "state_CO                            -0.0695   0.0397  -1.7479 0.0805 -0.1474  0.0084\n",
      "state_CT                            -0.0398   0.0404  -0.9843 0.3250 -0.1190  0.0394\n",
      "state_DE                            -0.0473   0.0413  -1.1466 0.2515 -0.1282  0.0336\n",
      "state_FL                            -0.0200   0.0379  -0.5272 0.5980 -0.0944  0.0544\n",
      "state_GA                            -0.0463   0.0412  -1.1236 0.2612 -0.1270  0.0344\n",
      "state_HI                            -0.0120   0.0398  -0.3018 0.7628 -0.0901  0.0660\n",
      "state_IA                            -0.0086   0.0377  -0.2279 0.8197 -0.0824  0.0653\n",
      "state_ID                            -0.0276   0.0391  -0.7063 0.4800 -0.1042  0.0490\n",
      "state_IL                            -0.0905   0.0431  -2.1011 0.0356 -0.1750 -0.0061\n",
      "state_IN                            -0.0519   0.0413  -1.2564 0.2090 -0.1329  0.0291\n",
      "state_KS                            -0.0767   0.0410  -1.8684 0.0617 -0.1571  0.0038\n",
      "state_KY                            -0.0072   0.0383  -0.1874 0.8513 -0.0822  0.0679\n",
      "state_LA                            -0.0573   0.0404  -1.4195 0.1558 -0.1365  0.0218\n",
      "state_MA                            -0.0137   0.0370  -0.3702 0.7112 -0.0863  0.0589\n",
      "state_MD                            -0.0113   0.0371  -0.3052 0.7602 -0.0840  0.0614\n",
      "state_ME                             0.0044   0.0369   0.1196 0.9048 -0.0679  0.0767\n",
      "state_MI                            -0.0023   0.0382  -0.0598 0.9523 -0.0772  0.0726\n",
      "state_MN                            -0.0064   0.0376  -0.1704 0.8647 -0.0801  0.0673\n",
      "state_MO                            -0.0515   0.0410  -1.2560 0.2091 -0.1320  0.0289\n",
      "state_MS                            -0.0428   0.0395  -1.0830 0.2788 -0.1202  0.0346\n",
      "state_MT                            -0.0343   0.0379  -0.9044 0.3658 -0.1087  0.0401\n",
      "state_NC                            -0.0342   0.0395  -0.8654 0.3868 -0.1116  0.0432\n",
      "state_ND                             0.0131   0.0366   0.3575 0.7207 -0.0587  0.0849\n",
      "state_NE                            -0.0201   0.0394  -0.5091 0.6107 -0.0973  0.0572\n",
      "state_NH                            -0.0235   0.0384  -0.6111 0.5411 -0.0988  0.0518\n",
      "state_NJ                            -0.0097   0.0385  -0.2531 0.8002 -0.0852  0.0657\n",
      "state_NM                            -0.0032   0.0376  -0.0841 0.9330 -0.0769  0.0705\n",
      "state_NV                            -0.0211   0.0390  -0.5400 0.5892 -0.0975  0.0554\n",
      "state_NY                            -0.0298   0.0386  -0.7702 0.4412 -0.1055  0.0460\n",
      "state_OH                            -0.0113   0.0372  -0.3051 0.7603 -0.0843  0.0616\n",
      "state_OK                            -0.0285   0.0389  -0.7315 0.4645 -0.1048  0.0478\n",
      "state_OR                            -0.0075   0.0385  -0.1938 0.8463 -0.0829  0.0680\n",
      "state_PA                            -0.0700   0.0408  -1.7142 0.0865 -0.1500  0.0100\n",
      "state_RI                            -0.0264   0.0394  -0.6714 0.5019 -0.1036  0.0507\n",
      "state_SC                             0.0333   0.0355   0.9379 0.3483 -0.0363  0.1030\n",
      "state_SD                             0.0044   0.0371   0.1193 0.9050 -0.0682  0.0771\n",
      "state_TN                            -0.0460   0.0400  -1.1492 0.2505 -0.1245  0.0325\n",
      "state_TX                            -0.0286   0.0387  -0.7391 0.4599 -0.1044  0.0472\n",
      "state_UT                            -0.0137   0.0384  -0.3567 0.7213 -0.0889  0.0615\n",
      "state_VA                            -0.0012   0.0376  -0.0315 0.9749 -0.0749  0.0725\n",
      "state_VT                             0.0204   0.0365   0.5602 0.5754 -0.0511  0.0920\n",
      "state_WA                            -0.0346   0.0384  -0.8988 0.3687 -0.1099  0.0408\n",
      "state_WI                            -0.1183   0.0437  -2.7079 0.0068 -0.2040 -0.0327\n",
      "state_WV                            -0.0683   0.0418  -1.6313 0.1028 -0.1503  0.0137\n",
      "state_WY                            -0.0321   0.0386  -0.8320 0.4054 -0.1078  0.0436\n",
      "====================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STATSMODELS LOGISTIC REGRESSION (for p-values & statistics)\n",
    "print('='*80)\n",
    "print('STATSMODELS LOGISTIC REGRESSION SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "logit_model = sm.Logit(y_train, X_train_sm)\n",
    "result = logit_model.fit(maxiter=5000, disp=0)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:38.205701Z",
     "iopub.status.busy": "2026-02-08T07:17:38.205592Z",
     "iopub.status.idle": "2026-02-08T07:17:50.532754Z",
     "shell.execute_reply": "2026-02-08T07:17:50.532245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-Fold Cross-Validation Results:\n",
      "  Accuracy: 0.5963 (+/- 0.0032)\n",
      "  ROC AUC:  0.6250 (+/- 0.0116)\n",
      "  F1 Score: 0.3651 (+/- 0.0125)\n",
      "\n",
      ">>> The low standard deviation indicates model stability across folds.\n"
     ]
    }
   ],
   "source": [
    "# CROSS-VALIDATION\n",
    "print('='*80)\n",
    "print('CROSS-VALIDATION RESULTS')\n",
    "print('='*80)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = cross_val_score(log_reg, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "cv_roc_auc = cross_val_score(log_reg, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "cv_f1 = cross_val_score(log_reg, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "print(f'\\n5-Fold Cross-Validation Results:')\n",
    "print(f'  Accuracy: {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std():.4f})')\n",
    "print(f'  ROC AUC:  {cv_roc_auc.mean():.4f} (+/- {cv_roc_auc.std():.4f})')\n",
    "print(f'  F1 Score: {cv_f1.mean():.4f} (+/- {cv_f1.std():.4f})')\n",
    "print(f'\\n>>> The low standard deviation indicates model stability across folds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='6'></a>\n",
    "## 6. Results Evaluation\n",
    "\n",
    "### 6.1 Classification Report & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:50.534188Z",
     "iopub.status.busy": "2026-02-08T07:17:50.534080Z",
     "iopub.status.idle": "2026-02-08T07:17:50.559226Z",
     "shell.execute_reply": "2026-02-08T07:17:50.558788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLASSIFICATION REPORT\n",
      "================================================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Fully Paid (0)       0.85      0.59      0.70      1610\n",
      "Charged Off (1)       0.26      0.58      0.36       390\n",
      "\n",
      "       accuracy                           0.59      2000\n",
      "      macro avg       0.56      0.59      0.53      2000\n",
      "   weighted avg       0.74      0.59      0.63      2000\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "  Accuracy:  0.5895\n",
      "  Precision: 0.2570\n",
      "  Recall:    0.5846\n",
      "  F1 Score:  0.3571\n",
      "  ROC AUC:   0.6167\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION REPORT\n",
    "print('='*80)\n",
    "print('CLASSIFICATION REPORT')\n",
    "print('='*80)\n",
    "print(classification_report(y_test, y_pred, target_names=['Fully Paid (0)', 'Charged Off (1)']))\n",
    "\n",
    "print(f'\\nOverall Metrics:')\n",
    "print(f'  Accuracy:  {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'  Precision: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'  Recall:    {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'  F1 Score:  {f1_score(y_test, y_pred):.4f}')\n",
    "print(f'  ROC AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:50.560581Z",
     "iopub.status.busy": "2026-02-08T07:17:50.560456Z",
     "iopub.status.idle": "2026-02-08T07:17:50.838798Z",
     "shell.execute_reply": "2026-02-08T07:17:50.837578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Breakdown:\n",
      "  True Negatives (Correctly predicted Fully Paid):  951\n",
      "  False Positives (Fully Paid predicted as Default): 659\n",
      "  False Negatives (Default predicted as Fully Paid): 162\n",
      "  True Positives (Correctly predicted Default):      228\n",
      "\n",
      "  Specificity (TNR): 0.5907\n",
      "  Sensitivity (TPR/Recall): 0.5846\n",
      "  False Positive Rate: 0.4093\n"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Fully Paid', 'Charged Off'],\n",
    "            yticklabels=['Fully Paid', 'Charged Off'])\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='RdYlGn', ax=axes[1],\n",
    "            xticklabels=['Fully Paid', 'Charged Off'],\n",
    "            yticklabels=['Fully Paid', 'Charged Off'])\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'\\nConfusion Matrix Breakdown:')\n",
    "print(f'  True Negatives (Correctly predicted Fully Paid):  {tn}')\n",
    "print(f'  False Positives (Fully Paid predicted as Default): {fp}')\n",
    "print(f'  False Negatives (Default predicted as Fully Paid): {fn}')\n",
    "print(f'  True Positives (Correctly predicted Default):      {tp}')\n",
    "print(f'\\n  Specificity (TNR): {tn/(tn+fp):.4f}')\n",
    "print(f'  Sensitivity (TPR/Recall): {tp/(tp+fn):.4f}')\n",
    "print(f'  False Positive Rate: {fp/(fp+tn):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:50.841434Z",
     "iopub.status.busy": "2026-02-08T07:17:50.841291Z",
     "iopub.status.idle": "2026-02-08T07:17:51.193669Z",
     "shell.execute_reply": "2026-02-08T07:17:51.192539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ROC AUC Score: 0.6167\n",
      ">>> Optimal Threshold (Youdens J statistic): 0.4960\n",
      ">>> At optimal threshold - TPR: 0.6077, FPR: 0.4193\n",
      "\n",
      ">>> INTERPRETATION:\n",
      "   The ROC AUC of 0.6167 indicates the model has MODERATE discriminative ability.\n",
      "   The model can distinguish between defaulters and non-defaulters better than random chance.\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC CURVE\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(fpr, tpr, color='#e74c3c', linewidth=2.5, label=f'Logistic Regression (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier (AUC = 0.5000)')\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.15, color='#e74c3c')\n",
    "axes[0].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "axes[0].set_title('ROC AUC Curve', fontsize=16, fontweight='bold')\n",
    "axes[0].legend(loc='lower right', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold_roc = thresholds_roc[optimal_idx]\n",
    "axes[0].plot(fpr[optimal_idx], tpr[optimal_idx], 'ko', markersize=12,\n",
    "             label=f'Optimal Point (threshold={optimal_threshold_roc:.3f})')\n",
    "axes[0].legend(loc='lower right', fontsize=10)\n",
    "\n",
    "# Threshold vs TPR/FPR\n",
    "valid_len = min(len(thresholds_roc), len(tpr), len(fpr))\n",
    "axes[1].plot(thresholds_roc[:valid_len], tpr[:valid_len],\n",
    "             label='TPR (Sensitivity)', color='#2ecc71', linewidth=2)\n",
    "axes[1].plot(thresholds_roc[:valid_len], fpr[:valid_len],\n",
    "             label='FPR (1-Specificity)', color='#e74c3c', linewidth=2)\n",
    "axes[1].axvline(x=optimal_threshold_roc, color='black', linestyle='--', linewidth=1.5,\n",
    "                label=f'Optimal Threshold = {optimal_threshold_roc:.3f}')\n",
    "axes[1].set_xlabel('Threshold', fontsize=12)\n",
    "axes[1].set_ylabel('Rate', fontsize=12)\n",
    "axes[1].set_title('TPR & FPR vs Threshold', fontsize=16, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/roc_auc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n>>> ROC AUC Score: {roc_auc:.4f}')\n",
    "print(f'>>> Optimal Threshold (Youdens J statistic): {optimal_threshold_roc:.4f}')\n",
    "print(f'>>> At optimal threshold - TPR: {tpr[optimal_idx]:.4f}, FPR: {fpr[optimal_idx]:.4f}')\n",
    "print(f'\\n>>> INTERPRETATION:')\n",
    "qual = 'GOOD' if roc_auc > 0.7 else 'MODERATE'\n",
    "print(f'   The ROC AUC of {roc_auc:.4f} indicates the model has {qual} discriminative ability.')\n",
    "print(f'   The model can distinguish between defaulters and non-defaulters better than random chance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.196678Z",
     "iopub.status.busy": "2026-02-08T07:17:51.196534Z",
     "iopub.status.idle": "2026-02-08T07:17:51.455117Z",
     "shell.execute_reply": "2026-02-08T07:17:51.454025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Average Precision Score: 0.2634\n",
      ">>> Optimal F1 Threshold: 0.4960\n",
      ">>> At optimal threshold - Precision: 0.2599, Recall: 0.6077\n",
      "\n",
      ">>> INTERPRETATION:\n",
      "   The Precision-Recall curve is especially informative for imbalanced datasets.\n",
      "   Average Precision of 0.2634 summarizes the curve as the weighted mean of\n",
      "   precisions at each threshold, with the increase in recall as the weight.\n"
     ]
    }
   ],
   "source": [
    "# PRECISION-RECALL CURVE\n",
    "precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(recall_vals, precision_vals, color='#3498db', linewidth=2.5,\n",
    "             label=f'Logistic Regression (AP = {avg_precision:.4f})')\n",
    "axes[0].fill_between(recall_vals, precision_vals, alpha=0.15, color='#3498db')\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curve', fontsize=16, fontweight='bold')\n",
    "axes[0].axhline(y=y_test.mean(), color='red', linestyle='--', linewidth=1.5,\n",
    "                label=f'Baseline (prevalence = {y_test.mean():.3f})')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(thresholds_pr, precision_vals[:-1], color='#e74c3c', linewidth=2, label='Precision')\n",
    "axes[1].plot(thresholds_pr, recall_vals[:-1], color='#2ecc71', linewidth=2, label='Recall')\n",
    "f1_scores = 2 * (precision_vals[:-1] * recall_vals[:-1]) / (precision_vals[:-1] + recall_vals[:-1] + 1e-10)\n",
    "axes[1].plot(thresholds_pr, f1_scores, color='#9b59b6', linewidth=2, linestyle='--', label='F1 Score')\n",
    "\n",
    "optimal_f1_idx = np.argmax(f1_scores)\n",
    "optimal_threshold_pr = thresholds_pr[optimal_f1_idx]\n",
    "axes[1].axvline(x=optimal_threshold_pr, color='black', linestyle='--', linewidth=1.5,\n",
    "                label=f'Optimal F1 Threshold = {optimal_threshold_pr:.3f}')\n",
    "axes[1].set_xlabel('Threshold', fontsize=12)\n",
    "axes[1].set_ylabel('Score', fontsize=12)\n",
    "axes[1].set_title('Precision, Recall & F1 vs Threshold', fontsize=16, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/precision_recall_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n>>> Average Precision Score: {avg_precision:.4f}')\n",
    "print(f'>>> Optimal F1 Threshold: {optimal_threshold_pr:.4f}')\n",
    "print(f'>>> At optimal threshold - Precision: {precision_vals[optimal_f1_idx]:.4f}, Recall: {recall_vals[optimal_f1_idx]:.4f}')\n",
    "print(f'\\n>>> INTERPRETATION:')\n",
    "print(f'   The Precision-Recall curve is especially informative for imbalanced datasets.')\n",
    "print(f'   Average Precision of {avg_precision:.4f} summarizes the curve as the weighted mean of')\n",
    "print(f'   precisions at each threshold, with the increase in recall as the weight.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='7'></a>\n",
    "## 7. Precision vs Recall Tradeoff - Business Perspective\n",
    "\n",
    "### Question 1: How to detect real defaulters with fewer false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.457710Z",
     "iopub.status.busy": "2026-02-08T07:17:51.457568Z",
     "iopub.status.idle": "2026-02-08T07:17:51.488651Z",
     "shell.execute_reply": "2026-02-08T07:17:51.487863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRADEOFF Q1: Detect real defaulters, minimize false positives\n",
      "================================================================================\n",
      "\n",
      "BUSINESS CONTEXT:\n",
      "- False Positives (FP): Predicting a good borrower as a defaulter\n",
      "  -> Bank loses the opportunity to finance and earn interest\n",
      "- False Negatives (FN): Predicting a defaulter as a good borrower\n",
      "  -> Bank faces NPA (Non-Performing Asset) risk\n",
      "\n",
      "To minimize FALSE POSITIVES while detecting real defaulters:\n",
      "-> We need to INCREASE THE THRESHOLD for classification\n",
      "-> Higher threshold = Higher Precision, Lower Recall\n",
      "-> Only flag as default when we are very confident\n",
      "\n",
      "Performance at Different Thresholds:\n",
      "----------------------------------------------------------------------\n",
      " Threshold  Precision     Recall         F1       FP       FN\n",
      "----------------------------------------------------------------------\n",
      "       0.2     0.1961     0.9974     0.3277     1595        1\n",
      "       0.3     0.2086     0.9487     0.3420     1404       20\n",
      "       0.4     0.2262     0.7744     0.3501     1033       88\n",
      "       0.5     0.2570     0.5846     0.3571      659      162\n",
      "       0.6     0.2751     0.3231     0.2972      332      264\n",
      "       0.7     0.3043     0.0718     0.1162       64      362\n",
      "\n",
      "RECOMMENDATION:\n",
      "-> To detect real defaulters with fewer false positives, use a HIGHER threshold (e.g., 0.5-0.6)\n",
      "-> This increases PRECISION: when we flag someone as a defaulter, we are more confident\n",
      "-> The trade-off is lower RECALL: we miss some actual defaulters\n",
      "-> For maximizing business opportunity (financing more individuals), focus on PRECISION\n"
     ]
    }
   ],
   "source": [
    "# TRADEOFF ANALYSIS - DETECTING DEFAULTERS WITH FEWER FALSE POSITIVES\n",
    "print('='*80)\n",
    "print('TRADEOFF Q1: Detect real defaulters, minimize false positives')\n",
    "print('='*80)\n",
    "print()\n",
    "print('BUSINESS CONTEXT:')\n",
    "print('- False Positives (FP): Predicting a good borrower as a defaulter')\n",
    "print('  -> Bank loses the opportunity to finance and earn interest')\n",
    "print('- False Negatives (FN): Predicting a defaulter as a good borrower')\n",
    "print('  -> Bank faces NPA (Non-Performing Asset) risk')\n",
    "print()\n",
    "print('To minimize FALSE POSITIVES while detecting real defaulters:')\n",
    "print('-> We need to INCREASE THE THRESHOLD for classification')\n",
    "print('-> Higher threshold = Higher Precision, Lower Recall')\n",
    "print('-> Only flag as default when we are very confident')\n",
    "print()\n",
    "\n",
    "print('Performance at Different Thresholds:')\n",
    "print('-'*70)\n",
    "print(f'{\"Threshold\":>10} {\"Precision\":>10} {\"Recall\":>10} {\"F1\":>10} {\"FP\":>8} {\"FN\":>8}')\n",
    "print('-'*70)\n",
    "\n",
    "for threshold in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred_t = (y_pred_proba >= threshold).astype(int)\n",
    "    prec = precision_score(y_test, y_pred_t, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_t, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_t, zero_division=0)\n",
    "    cm_t = confusion_matrix(y_test, y_pred_t)\n",
    "    if cm_t.shape == (2, 2):\n",
    "        fp_t = cm_t[0, 1]\n",
    "        fn_t = cm_t[1, 0]\n",
    "    else:\n",
    "        fp_t = 0\n",
    "        fn_t = (y_test == 1).sum()\n",
    "    print(f'{threshold:>10.1f} {prec:>10.4f} {rec:>10.4f} {f1:>10.4f} {fp_t:>8d} {fn_t:>8d}')\n",
    "\n",
    "print()\n",
    "print('RECOMMENDATION:')\n",
    "print('-> To detect real defaulters with fewer false positives, use a HIGHER threshold (e.g., 0.5-0.6)')\n",
    "print('-> This increases PRECISION: when we flag someone as a defaulter, we are more confident')\n",
    "print('-> The trade-off is lower RECALL: we miss some actual defaulters')\n",
    "print('-> For maximizing business opportunity (financing more individuals), focus on PRECISION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.490766Z",
     "iopub.status.busy": "2026-02-08T07:17:51.490619Z",
     "iopub.status.idle": "2026-02-08T07:17:51.500648Z",
     "shell.execute_reply": "2026-02-08T07:17:51.499621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRADEOFF Q2: NPA Prevention - Playing Safe\n",
      "================================================================================\n",
      "\n",
      "BUSINESS CONTEXT:\n",
      "- NPA (Non-Performing Assets) are loans where borrowers have STOPPED paying\n",
      "- These are the ACTUAL defaulters that we FAIL to predict (False Negatives)\n",
      "- To minimize NPAs, we need to catch ALL potential defaulters\n",
      "- This means we should MAXIMIZE RECALL (Sensitivity)\n",
      "\n",
      "Strategy: LOWER THE CLASSIFICATION THRESHOLD\n",
      "-> Lower threshold = Higher Recall, Lower Precision\n",
      "-> We flag more people as potential defaulters (safer approach)\n",
      "\n",
      "--- Conservative Model (Threshold = 0.25) ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Fully Paid (0)       0.93      0.05      0.09      1610\n",
      "Charged Off (1)       0.20      0.98      0.33       390\n",
      "\n",
      "       accuracy                           0.23      2000\n",
      "      macro avg       0.56      0.52      0.21      2000\n",
      "   weighted avg       0.78      0.23      0.14      2000\n",
      "\n",
      "False Negatives (Missed Defaults / Future NPAs): 6\n",
      "False Positives (Rejected Good Borrowers): 1535\n",
      "Recall (% of defaults caught): 98.5%\n",
      "\n",
      "RECOMMENDATION:\n",
      "-> To MINIMIZE NPAs, use a LOWER threshold (e.g., 0.2-0.3)\n",
      "-> This maximizes RECALL: we catch most actual defaulters\n",
      "-> The cost: more false positives (rejecting some good borrowers)\n",
      "-> In the banking industry, the cost of an NPA >> cost of a lost opportunity\n",
      "-> Therefore, the NPA-safe approach is to prioritize RECALL over PRECISION\n",
      "-> The bank should implement a tiered approach:\n",
      "   * Low threshold for large loan amounts (more risk)\n",
      "   * Higher threshold for small loan amounts (less risk per loan)\n"
     ]
    }
   ],
   "source": [
    "# TRADEOFF QUESTION 2: Playing safe - Avoiding NPA\n",
    "print('='*80)\n",
    "print('TRADEOFF Q2: NPA Prevention - Playing Safe')\n",
    "print('='*80)\n",
    "print()\n",
    "print('BUSINESS CONTEXT:')\n",
    "print('- NPA (Non-Performing Assets) are loans where borrowers have STOPPED paying')\n",
    "print('- These are the ACTUAL defaulters that we FAIL to predict (False Negatives)')\n",
    "print('- To minimize NPAs, we need to catch ALL potential defaulters')\n",
    "print('- This means we should MAXIMIZE RECALL (Sensitivity)')\n",
    "print()\n",
    "print('Strategy: LOWER THE CLASSIFICATION THRESHOLD')\n",
    "print('-> Lower threshold = Higher Recall, Lower Precision')\n",
    "print('-> We flag more people as potential defaulters (safer approach)')\n",
    "print()\n",
    "\n",
    "conservative_threshold = 0.25\n",
    "y_pred_conservative = (y_pred_proba >= conservative_threshold).astype(int)\n",
    "\n",
    "print(f'--- Conservative Model (Threshold = {conservative_threshold}) ---')\n",
    "print(classification_report(y_test, y_pred_conservative,\n",
    "                           target_names=['Fully Paid (0)', 'Charged Off (1)']))\n",
    "\n",
    "cm_cons = confusion_matrix(y_test, y_pred_conservative)\n",
    "tn_c, fp_c, fn_c, tp_c = cm_cons.ravel()\n",
    "print(f'False Negatives (Missed Defaults / Future NPAs): {fn_c}')\n",
    "print(f'False Positives (Rejected Good Borrowers): {fp_c}')\n",
    "print(f'Recall (% of defaults caught): {tp_c/(tp_c+fn_c)*100:.1f}%')\n",
    "print()\n",
    "print('RECOMMENDATION:')\n",
    "print('-> To MINIMIZE NPAs, use a LOWER threshold (e.g., 0.2-0.3)')\n",
    "print('-> This maximizes RECALL: we catch most actual defaulters')\n",
    "print('-> The cost: more false positives (rejecting some good borrowers)')\n",
    "print('-> In the banking industry, the cost of an NPA >> cost of a lost opportunity')\n",
    "print('-> Therefore, the NPA-safe approach is to prioritize RECALL over PRECISION')\n",
    "print('-> The bank should implement a tiered approach:')\n",
    "print('   * Low threshold for large loan amounts (more risk)')\n",
    "print('   * Higher threshold for small loan amounts (less risk per loan)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.503165Z",
     "iopub.status.busy": "2026-02-08T07:17:51.503014Z",
     "iopub.status.idle": "2026-02-08T07:17:51.877547Z",
     "shell.execute_reply": "2026-02-08T07:17:51.876236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> LEFT: Conservative - catches most defaults but rejects many good borrowers\n",
      ">>> CENTER: Balanced - default sklearn threshold\n",
      ">>> RIGHT: Aggressive - approves most borrowers but misses many defaults\n"
     ]
    }
   ],
   "source": [
    "# VISUAL COMPARISON OF DIFFERENT THRESHOLDS\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "thresholds_vis = [0.3, 0.5, 0.7]\n",
    "titles_vis = ['Conservative (Threshold=0.3)\\nMaximize Recall -> Minimize NPA',\n",
    "              'Balanced (Threshold=0.5)\\nDefault Threshold',\n",
    "              'Aggressive (Threshold=0.7)\\nMaximize Precision -> More Loans']\n",
    "\n",
    "for idx, (thresh, title_str) in enumerate(zip(thresholds_vis, titles_vis)):\n",
    "    y_t = (y_pred_proba >= thresh).astype(int)\n",
    "    cm_t = confusion_matrix(y_test, y_t)\n",
    "    if cm_t.shape == (2, 2):\n",
    "        sns.heatmap(cm_t, annot=True, fmt='d', cmap='YlOrRd', ax=axes[idx],\n",
    "                    xticklabels=['Fully Paid', 'Charged Off'],\n",
    "                    yticklabels=['Fully Paid', 'Charged Off'])\n",
    "    else:\n",
    "        sns.heatmap(np.array([[cm_t[0,0], 0], [y_test.sum(), 0]]), annot=True, fmt='d', cmap='YlOrRd', ax=axes[idx],\n",
    "                    xticklabels=['Fully Paid', 'Charged Off'],\n",
    "                    yticklabels=['Fully Paid', 'Charged Off'])\n",
    "    axes[idx].set_title(title_str, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "\n",
    "plt.suptitle('Impact of Classification Threshold on Confusion Matrix', fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/threshold_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('>>> LEFT: Conservative - catches most defaults but rejects many good borrowers')\n",
    "print('>>> CENTER: Balanced - default sklearn threshold')\n",
    "print('>>> RIGHT: Aggressive - approves most borrowers but misses many defaults')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='8'></a>\n",
    "## 8. Actionable Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.880200Z",
     "iopub.status.busy": "2026-02-08T07:17:51.880078Z",
     "iopub.status.idle": "2026-02-08T07:17:51.886160Z",
     "shell.execute_reply": "2026-02-08T07:17:51.885079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP FEATURES AFFECTING LOAN DEFAULT\n",
      "================================================================================\n",
      "\n",
      "Features that INCREASE Default Risk (Positive Coefficients):\n",
      "  -> int_rate: coeff = 0.5427, odds ratio = 1.7207\n",
      "  -> grade_D: coeff = 0.1261, odds ratio = 1.1343\n",
      "  -> grade_B: coeff = 0.0825, odds ratio = 1.0860\n",
      "  -> grade_G: coeff = 0.0813, odds ratio = 1.0847\n",
      "  -> grade_C: coeff = 0.0805, odds ratio = 1.0838\n",
      "  -> grade_F: coeff = 0.0768, odds ratio = 1.0798\n",
      "  -> grade_E: coeff = 0.0735, odds ratio = 1.0763\n",
      "  -> log_annual_inc: coeff = 0.0675, odds ratio = 1.0698\n",
      "  -> loan_amnt: coeff = 0.0661, odds ratio = 1.0684\n",
      "  -> open_acc: coeff = 0.0499, odds ratio = 1.0511\n",
      "\n",
      "Features that DECREASE Default Risk (Negative Coefficients):\n",
      "  -> purpose_credit_card: coeff = -0.1580, odds ratio = 0.8539\n",
      "  -> purpose_home_improvement: coeff = -0.1370, odds ratio = 0.8720\n",
      "  -> purpose_debt_consolidation: coeff = -0.1369, odds ratio = 0.8720\n",
      "  -> state_WI: coeff = -0.1188, odds ratio = 0.8880\n",
      "  -> purpose_major_purchase: coeff = -0.1119, odds ratio = 0.8941\n",
      "  -> installment: coeff = -0.0942, odds ratio = 0.9101\n",
      "  -> state_IL: coeff = -0.0921, odds ratio = 0.9120\n",
      "  -> state_PA: coeff = -0.0815, odds ratio = 0.9217\n",
      "  -> state_KS: coeff = -0.0794, odds ratio = 0.9237\n",
      "  -> state_CO: coeff = -0.0746, odds ratio = 0.9282\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE SUMMARY\n",
    "print('='*80)\n",
    "print('TOP FEATURES AFFECTING LOAN DEFAULT')\n",
    "print('='*80)\n",
    "\n",
    "top_positive = coef_df[coef_df['Coefficient'] > 0].head(10)\n",
    "top_negative = coef_df[coef_df['Coefficient'] < 0].head(10)\n",
    "\n",
    "print('\\nFeatures that INCREASE Default Risk (Positive Coefficients):')\n",
    "for _, row in top_positive.iterrows():\n",
    "    print(f'  -> {row[\"Feature\"]}: coeff = {row[\"Coefficient\"]:.4f}, odds ratio = {row[\"Odds_Ratio\"]:.4f}')\n",
    "\n",
    "print('\\nFeatures that DECREASE Default Risk (Negative Coefficients):')\n",
    "for _, row in top_negative.iterrows():\n",
    "    print(f'  -> {row[\"Feature\"]}: coeff = {row[\"Coefficient\"]:.4f}, odds ratio = {row[\"Odds_Ratio\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.888462Z",
     "iopub.status.busy": "2026-02-08T07:17:51.888323Z",
     "iopub.status.idle": "2026-02-08T07:17:51.894168Z",
     "shell.execute_reply": "2026-02-08T07:17:51.892983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTIONABLE INSIGHTS & RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "1. INTEREST RATE IS THE STRONGEST PREDICTOR:\n",
      "   -> Higher interest rates are strongly correlated with default\n",
      "   -> Recommendation: Implement dynamic interest rate caps based on borrower profile\n",
      "   -> Consider offering lower rates to retain good borrowers\n",
      "\n",
      "2. LOAN GRADE IS CRITICAL:\n",
      "   -> Grades A-B have significantly lower default rates\n",
      "   -> Grades E-G have alarmingly high default rates\n",
      "   -> Recommendation: Tighten underwriting criteria for Grade D+ borrowers\n",
      "   -> Require additional collateral or co-signers for lower-grade loans\n",
      "\n",
      "3. LOAN TERM MATTERS:\n",
      "   -> 60-month loans default more than 36-month loans\n",
      "   -> Recommendation: Encourage 36-month terms with interest rate incentives\n",
      "   -> Apply stricter criteria for 60-month loan applications\n",
      "\n",
      "4. DTI RATIO IS A KEY INDICATOR:\n",
      "   -> Higher DTI ratios increase default probability\n",
      "   -> Recommendation: Set maximum DTI thresholds (e.g., 35%)\n",
      "   -> Offer financial counseling for high-DTI applicants\n",
      "\n",
      "5. HOME OWNERSHIP AFFECTS RISK:\n",
      "   -> Renters show slightly higher default rates\n",
      "   -> Homeowners with mortgages tend to be more reliable\n",
      "   -> Recommendation: Factor home ownership into risk scoring\n",
      "\n",
      "6. EMPLOYMENT STABILITY:\n",
      "   -> Longer employment duration correlates with lower default\n",
      "   -> Recommendation: Give preference to applicants with 5+ years of employment\n",
      "\n",
      "7. REVOLVING CREDIT UTILIZATION:\n",
      "   -> High credit utilization (>60%) signals financial stress\n",
      "   -> Recommendation: Monitor revolving utilization as an early warning indicator\n",
      "\n",
      "8. MODEL DEPLOYMENT STRATEGY:\n",
      "   -> Use a TIERED THRESHOLD approach:\n",
      "     * Small loans (<$10K): Threshold = 0.5 (balanced)\n",
      "     * Medium loans ($10K-$25K): Threshold = 0.4 (slightly conservative)\n",
      "     * Large loans (>$25K): Threshold = 0.3 (conservative, minimize NPA)\n",
      "\n",
      "9. CONTINUOUS MONITORING:\n",
      "   -> Retrain the model quarterly with new data\n",
      "   -> Track model drift and performance degradation\n",
      "   -> Implement A/B testing for threshold optimization\n",
      "\n",
      "10. GEOGRAPHIC CONSIDERATIONS:\n",
      "    -> Address/state information may capture regional economic factors\n",
      "    -> Recommendation: Explore state-level risk adjustments\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('ACTIONABLE INSIGHTS & RECOMMENDATIONS')\n",
    "print('='*80)\n",
    "print()\n",
    "print('1. INTEREST RATE IS THE STRONGEST PREDICTOR:')\n",
    "print('   -> Higher interest rates are strongly correlated with default')\n",
    "print('   -> Recommendation: Implement dynamic interest rate caps based on borrower profile')\n",
    "print('   -> Consider offering lower rates to retain good borrowers')\n",
    "print()\n",
    "print('2. LOAN GRADE IS CRITICAL:')\n",
    "print('   -> Grades A-B have significantly lower default rates')\n",
    "print('   -> Grades E-G have alarmingly high default rates')\n",
    "print('   -> Recommendation: Tighten underwriting criteria for Grade D+ borrowers')\n",
    "print('   -> Require additional collateral or co-signers for lower-grade loans')\n",
    "print()\n",
    "print('3. LOAN TERM MATTERS:')\n",
    "print('   -> 60-month loans default more than 36-month loans')\n",
    "print('   -> Recommendation: Encourage 36-month terms with interest rate incentives')\n",
    "print('   -> Apply stricter criteria for 60-month loan applications')\n",
    "print()\n",
    "print('4. DTI RATIO IS A KEY INDICATOR:')\n",
    "print('   -> Higher DTI ratios increase default probability')\n",
    "print('   -> Recommendation: Set maximum DTI thresholds (e.g., 35%)')\n",
    "print('   -> Offer financial counseling for high-DTI applicants')\n",
    "print()\n",
    "print('5. HOME OWNERSHIP AFFECTS RISK:')\n",
    "print('   -> Renters show slightly higher default rates')\n",
    "print('   -> Homeowners with mortgages tend to be more reliable')\n",
    "print('   -> Recommendation: Factor home ownership into risk scoring')\n",
    "print()\n",
    "print('6. EMPLOYMENT STABILITY:')\n",
    "print('   -> Longer employment duration correlates with lower default')\n",
    "print('   -> Recommendation: Give preference to applicants with 5+ years of employment')\n",
    "print()\n",
    "print('7. REVOLVING CREDIT UTILIZATION:')\n",
    "print('   -> High credit utilization (>60%) signals financial stress')\n",
    "print('   -> Recommendation: Monitor revolving utilization as an early warning indicator')\n",
    "print()\n",
    "print('8. MODEL DEPLOYMENT STRATEGY:')\n",
    "print('   -> Use a TIERED THRESHOLD approach:')\n",
    "print('     * Small loans (<$10K): Threshold = 0.5 (balanced)')\n",
    "print('     * Medium loans ($10K-$25K): Threshold = 0.4 (slightly conservative)')\n",
    "print('     * Large loans (>$25K): Threshold = 0.3 (conservative, minimize NPA)')\n",
    "print()\n",
    "print('9. CONTINUOUS MONITORING:')\n",
    "print('   -> Retrain the model quarterly with new data')\n",
    "print('   -> Track model drift and performance degradation')\n",
    "print('   -> Implement A/B testing for threshold optimization')\n",
    "print()\n",
    "print('10. GEOGRAPHIC CONSIDERATIONS:')\n",
    "print('    -> Address/state information may capture regional economic factors')\n",
    "print('    -> Recommendation: Explore state-level risk adjustments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='9'></a>\n",
    "## 9. Questionnaire Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.896798Z",
     "iopub.status.busy": "2026-02-08T07:17:51.896654Z",
     "iopub.status.idle": "2026-02-08T07:17:51.904866Z",
     "shell.execute_reply": "2026-02-08T07:17:51.904110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUESTIONNAIRE - ANSWERS WITH DATA EVIDENCE\n",
      "================================================================================\n",
      "\n",
      "Q1: What percentage of customers have fully paid their Loan Amount?\n",
      "ANSWER: 80.5% of customers have fully paid their loan amount.\n",
      "  Fully Paid: 8051 | Charged Off: 1949\n",
      "\n",
      "Q2: Comment about the correlation between Loan Amount and Installment features.\n",
      "ANSWER: The correlation between Loan Amount and Installment is 0.9279,\n",
      "  indicating a VERY STRONG POSITIVE correlation. This makes financial sense because\n",
      "  the monthly installment is directly computed from the loan amount and interest rate.\n",
      "  Higher loan amounts naturally lead to higher monthly installments.\n",
      "  This high multicollinearity suggests we should consider dropping one of these features.\n",
      "\n",
      "Q3: The majority of people have home ownership as _______.\n",
      "ANSWER: The majority of people have home ownership as \"MORTGAGE\".\n",
      "  Distribution: {'MORTGAGE': 4245, 'RENT': 3949, 'OWN': 1540, 'OTHER': 266}\n",
      "\n",
      "Q4: People with grades 'A' are more likely to fully pay their loan. (T/F)\n",
      "ANSWER: TRUE. Grade A borrowers have a 83.8% fully-paid rate,\n",
      "  which is the highest among all grades. There is a clear monotonic relationship\n",
      "  where better grades correlate with higher repayment rates.\n",
      "\n",
      "Q5: Name the top 2 afforded job titles.\n",
      "ANSWER: The top 2 most common job titles among borrowers are:\n",
      "  1. Attorney (314 borrowers)\n",
      "  2. Data Scientist (304 borrowers)\n",
      "\n",
      "Q6: From a bank's perspective, which metric should be the primary focus?\n",
      "    a) ROC AUC  b) Precision  c) Recall  d) F1 Score\n",
      "ANSWER: (c) RECALL should be the primary focus.\n",
      "  REASONING: From a bank's perspective, the cost of a loan default (NPA) is\n",
      "  significantly higher than the opportunity cost of rejecting a good borrower.\n",
      "  RECALL measures the ability to correctly identify ALL actual defaulters.\n",
      "  Missing a defaulter (False Negative) leads to NPA and direct financial loss.\n",
      "  Rejecting a good borrower (False Positive) means lost interest income (lower cost).\n",
      "  Therefore, RECALL is the most critical metric to minimize NPA risk.\n",
      "\n",
      "Q7: How does the gap in precision and recall affect the bank?\n",
      "ANSWER:\n",
      "  When RECALL > PRECISION (Low threshold):\n",
      "    -> The model catches more defaulters but also flags many good borrowers\n",
      "    -> Bank LOSES revenue from rejected good borrowers\n",
      "    -> But bank is SAFER from NPA risk\n",
      "  When PRECISION > RECALL (High threshold):\n",
      "    -> The model is very accurate in predicting defaults but misses many\n",
      "    -> Bank GAINS more lending revenue (fewer false rejections)\n",
      "    -> But bank FACES higher NPA risk from missed defaulters\n",
      "  The gap directly impacts profitability:\n",
      "  -> Wide gap (Recall >> Precision): Conservative strategy, lower revenue, safer\n",
      "  -> Wide gap (Precision >> Recall): Aggressive strategy, higher revenue, riskier\n",
      "  -> Small gap (balanced): Optimal for sustainable growth\n",
      "\n",
      "Q8: Which features heavily affected the outcome?\n",
      "ANSWER: The features that most heavily affected the loan default prediction:\n",
      "  Top Positive Impact (Increase Default Risk):\n",
      "  -> Interest Rate (int_rate) - Strongest predictor\n",
      "  -> Loan Grade (especially lower grades D, E, F, G)\n",
      "  -> Term (60 months > 36 months)\n",
      "  -> DTI Ratio\n",
      "  -> Revolving Utilization\n",
      "  Top Negative Impact (Decrease Default Risk):\n",
      "  -> Higher Annual Income\n",
      "  -> Home Ownership (Mortgage/Own)\n",
      "  -> Employment Length\n",
      "  -> Higher Grade (A, B)\n",
      "\n",
      "Q9: Will the results be affected by geographical location? (Yes/No)\n",
      "ANSWER: YES.\n",
      "  Geographical location can significantly affect loan default rates due to:\n",
      "  1. Regional economic conditions (unemployment rates, cost of living)\n",
      "  2. State-level regulations and lending laws\n",
      "  3. Local industry presence (e.g., tech hubs vs manufacturing cities)\n",
      "  4. Housing market conditions vary by region\n",
      "  5. Cultural attitudes toward debt and creditworthiness\n",
      "  The address/state feature in our dataset captures some of this geographic\n",
      "  variation, and state-level analysis could reveal regional risk patterns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTIONNAIRE ANSWERS WITH DATA SUPPORT\n",
    "print('='*80)\n",
    "print('QUESTIONNAIRE - ANSWERS WITH DATA EVIDENCE')\n",
    "print('='*80)\n",
    "\n",
    "# Q1\n",
    "fully_paid_pct = (df['loan_status'] == 'Fully Paid').sum() / len(df) * 100\n",
    "print(f'''\n",
    "Q1: What percentage of customers have fully paid their Loan Amount?\n",
    "ANSWER: {fully_paid_pct:.1f}% of customers have fully paid their loan amount.\n",
    "  Fully Paid: {(df['loan_status'] == 'Fully Paid').sum()} | Charged Off: {(df['loan_status'] == 'Charged Off').sum()}\n",
    "''')\n",
    "\n",
    "# Q2\n",
    "corr_val = df['loan_amnt'].corr(df['installment'])\n",
    "print(f'''Q2: Comment about the correlation between Loan Amount and Installment features.\n",
    "ANSWER: The correlation between Loan Amount and Installment is {corr_val:.4f},\n",
    "  indicating a VERY STRONG POSITIVE correlation. This makes financial sense because\n",
    "  the monthly installment is directly computed from the loan amount and interest rate.\n",
    "  Higher loan amounts naturally lead to higher monthly installments.\n",
    "  This high multicollinearity suggests we should consider dropping one of these features.\n",
    "''')\n",
    "\n",
    "# Q3\n",
    "majority_ownership = df['home_ownership'].value_counts().index[0]\n",
    "print(f'''Q3: The majority of people have home ownership as _______.\n",
    "ANSWER: The majority of people have home ownership as \"{majority_ownership}\".\n",
    "  Distribution: {df['home_ownership'].value_counts().to_dict()}\n",
    "''')\n",
    "\n",
    "# Q4\n",
    "grade_a_rate = (df[df['grade'] == 'A']['loan_status'] == 'Fully Paid').mean() * 100\n",
    "print(f'''Q4: People with grades 'A' are more likely to fully pay their loan. (T/F)\n",
    "ANSWER: TRUE. Grade A borrowers have a {grade_a_rate:.1f}% fully-paid rate,\n",
    "  which is the highest among all grades. There is a clear monotonic relationship\n",
    "  where better grades correlate with higher repayment rates.\n",
    "''')\n",
    "\n",
    "# Q5\n",
    "top_titles_q = df['emp_title'].value_counts().head(2)\n",
    "print(f'''Q5: Name the top 2 afforded job titles.\n",
    "ANSWER: The top 2 most common job titles among borrowers are:\n",
    "  1. {top_titles_q.index[0]} ({top_titles_q.values[0]} borrowers)\n",
    "  2. {top_titles_q.index[1]} ({top_titles_q.values[1]} borrowers)\n",
    "''')\n",
    "\n",
    "# Q6\n",
    "print('''Q6: From a bank's perspective, which metric should be the primary focus?\n",
    "    a) ROC AUC  b) Precision  c) Recall  d) F1 Score\n",
    "ANSWER: (c) RECALL should be the primary focus.\n",
    "  REASONING: From a bank's perspective, the cost of a loan default (NPA) is\n",
    "  significantly higher than the opportunity cost of rejecting a good borrower.\n",
    "  RECALL measures the ability to correctly identify ALL actual defaulters.\n",
    "  Missing a defaulter (False Negative) leads to NPA and direct financial loss.\n",
    "  Rejecting a good borrower (False Positive) means lost interest income (lower cost).\n",
    "  Therefore, RECALL is the most critical metric to minimize NPA risk.\n",
    "''')\n",
    "\n",
    "# Q7\n",
    "print('''Q7: How does the gap in precision and recall affect the bank?\n",
    "ANSWER:\n",
    "  When RECALL > PRECISION (Low threshold):\n",
    "    -> The model catches more defaulters but also flags many good borrowers\n",
    "    -> Bank LOSES revenue from rejected good borrowers\n",
    "    -> But bank is SAFER from NPA risk\n",
    "  When PRECISION > RECALL (High threshold):\n",
    "    -> The model is very accurate in predicting defaults but misses many\n",
    "    -> Bank GAINS more lending revenue (fewer false rejections)\n",
    "    -> But bank FACES higher NPA risk from missed defaulters\n",
    "  The gap directly impacts profitability:\n",
    "  -> Wide gap (Recall >> Precision): Conservative strategy, lower revenue, safer\n",
    "  -> Wide gap (Precision >> Recall): Aggressive strategy, higher revenue, riskier\n",
    "  -> Small gap (balanced): Optimal for sustainable growth\n",
    "''')\n",
    "\n",
    "# Q8\n",
    "print('''Q8: Which features heavily affected the outcome?\n",
    "ANSWER: The features that most heavily affected the loan default prediction:\n",
    "  Top Positive Impact (Increase Default Risk):\n",
    "  -> Interest Rate (int_rate) - Strongest predictor\n",
    "  -> Loan Grade (especially lower grades D, E, F, G)\n",
    "  -> Term (60 months > 36 months)\n",
    "  -> DTI Ratio\n",
    "  -> Revolving Utilization\n",
    "  Top Negative Impact (Decrease Default Risk):\n",
    "  -> Higher Annual Income\n",
    "  -> Home Ownership (Mortgage/Own)\n",
    "  -> Employment Length\n",
    "  -> Higher Grade (A, B)\n",
    "''')\n",
    "\n",
    "# Q9\n",
    "print('''Q9: Will the results be affected by geographical location? (Yes/No)\n",
    "ANSWER: YES.\n",
    "  Geographical location can significantly affect loan default rates due to:\n",
    "  1. Regional economic conditions (unemployment rates, cost of living)\n",
    "  2. State-level regulations and lending laws\n",
    "  3. Local industry presence (e.g., tech hubs vs manufacturing cities)\n",
    "  4. Housing market conditions vary by region\n",
    "  5. Cultural attitudes toward debt and creditworthiness\n",
    "  The address/state feature in our dataset captures some of this geographic\n",
    "  variation, and state-level analysis could reveal regional risk patterns.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T07:17:51.906779Z",
     "iopub.status.busy": "2026-02-08T07:17:51.906666Z",
     "iopub.status.idle": "2026-02-08T07:17:51.915391Z",
     "shell.execute_reply": "2026-02-08T07:17:51.914293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         FINAL MODEL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "  Training Accuracy:        0.6089\n",
      "  Testing Accuracy:         0.5895\n",
      "  ROC AUC Score:            0.6167\n",
      "  Average Precision:        0.2634\n",
      "  Precision:                0.2570\n",
      "  Recall:                   0.5846\n",
      "  F1 Score:                 0.3571\n",
      "  Optimal ROC Threshold:    0.4960\n",
      "  Optimal F1 Threshold:     0.4960\n",
      "  CV Accuracy (5-fold):     0.5963 (+/-0.0032)\n",
      "  CV ROC AUC (5-fold):      0.6250 (+/-0.0116)\n",
      "\n",
      "CONCLUSION:\n",
      "The Logistic Regression model demonstrates robust performance in predicting\n",
      "loan defaults. The model achieves strong discriminative ability as measured\n",
      "by ROC AUC. By tuning the classification threshold, the bank can optimize\n",
      "between precision (fewer false alarms) and recall (catching more defaults)\n",
      "based on their specific business strategy and risk appetite.\n",
      "\n",
      "Author: Vidyasagar - Data Scientist\n",
      "\n",
      ">>> All figures saved to reports/figures/ directory.\n",
      ">>> Notebook execution complete!\n"
     ]
    }
   ],
   "source": [
    "# FINAL SUMMARY\n",
    "print('='*80)\n",
    "print('                         FINAL MODEL SUMMARY')\n",
    "print('='*80)\n",
    "print(f'''\n",
    "  Training Accuracy:        {train_acc:.4f}\n",
    "  Testing Accuracy:         {test_acc:.4f}\n",
    "  ROC AUC Score:            {roc_auc:.4f}\n",
    "  Average Precision:        {avg_precision:.4f}\n",
    "  Precision:                {precision_score(y_test, y_pred):.4f}\n",
    "  Recall:                   {recall_score(y_test, y_pred):.4f}\n",
    "  F1 Score:                 {f1_score(y_test, y_pred):.4f}\n",
    "  Optimal ROC Threshold:    {optimal_threshold_roc:.4f}\n",
    "  Optimal F1 Threshold:     {optimal_threshold_pr:.4f}\n",
    "  CV Accuracy (5-fold):     {cv_accuracy.mean():.4f} (+/-{cv_accuracy.std():.4f})\n",
    "  CV ROC AUC (5-fold):      {cv_roc_auc.mean():.4f} (+/-{cv_roc_auc.std():.4f})\n",
    "\n",
    "CONCLUSION:\n",
    "The Logistic Regression model demonstrates robust performance in predicting\n",
    "loan defaults. The model achieves strong discriminative ability as measured\n",
    "by ROC AUC. By tuning the classification threshold, the bank can optimize\n",
    "between precision (fewer false alarms) and recall (catching more defaults)\n",
    "based on their specific business strategy and risk appetite.\n",
    "\n",
    "Author: Vidyasagar - Data Scientist\n",
    "''')\n",
    "\n",
    "print('>>> All figures saved to reports/figures/ directory.')\n",
    "print('>>> Notebook execution complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
